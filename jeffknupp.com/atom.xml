<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Hackers Gonna Hack]]></title>
  <link href="http://www.jeffknupp.com/atom.xml" rel="self"/>
  <link href="http://www.jeffknupp.com/"/>
  <updated>2012-07-10T06:02:38-04:00</updated>
  <id>http://www.jeffknupp.com/</id>
  <author>
    <name><![CDATA[Jeff Knupp]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Software Optimization: A Systematic Approach]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/07/10/software-optimization-a-systematic-approach/"/>
    <updated>2012-07-10T05:25:00-04:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/07/10/software-optimization-a-systematic-approach</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>What follows is the first in a series of articles on developing a formal methodology
for software optimization I&#8217;ve been working on for some
time. Each week, I&#8217;ll post the newest installment here (they&#8217;re all written, I&#8217;m just
wary of dumping the whole thing here all at once). Feedback is of course welcome and
encouraged. The complete version will be available in epub format, as well as online
in a more readable style. I hope you enjoy reading this half as much as I enjoyed
writing it.</p>

<h2>Part 1: A Primer</h2>

<p>Software Optimization is a topic which receives a curious lack of coverage in
most Computer Science curricula. Even on the Internet, there are few resources
which approach the topic in any kind of structured manner.  Typically, a
programmer blogs about how they made a certain piece of code x times faster and
describes the series of changes made. These &#8220;optimization anecdotes&#8221; are
entertaining but rarely useful as a way to learn how to optimize one&#8217;s own code.
<em>The main problem in learning how to optimize code is that no one is actually
teaching it.</em></p>

<p>Especially in the enterprise, optimization is poorly understood by many developers. There are a number
of reasons for this: lack of understanding about OS level operations, lack of familiarity
with tools to aid optimization, and the difficulty in correctly anticipating bottlenecks
in one&#8217;s code, to name a few. Junior developers, lacking the proper experience
to even know where to start, often practice cargo-cult optimization, applying
optimizations they&#8217;ve seen or read about elsewhere without determining if they&#8217;re impactful and
appropriate.</p>

<p><em>It&#8217;s time the practice of software optimization had a homepage.</em></p>

<p>This series of articles will present a formalized, structured approach to
software optimization. While most of the examples will focus on Linux, the
methodology and ideas are universally applicable. A programmer on any other
OS should have no problem following along and get just as much
out of it. An embedded systems developer will find the low level details
different but the approach the same.</p>

<!--more-->


<h3>Reality Check</h3>

<p>This is the part where I&#8217;m supposed to tell you that after reading this series
you&#8217;ll be ready to amaze your boss by fixing all of the slow-performing
code in whatever it is you work on. Unfortunately, that won&#8217;t be the case. I must be
very clear about this point lest anyone have unreasonable expectations: Even
after reading this entire series and all of the background material mentioned,
becoming a skilled practitioner of optimization will likely require at least ten
years of professional development experience and at least two to three years
working on a performance critical system. It is not a skill one picks up all at
once; rather, it draws on the knowledge built over one&#8217;s career.
The study of optimization is not done in isolation. It necessarily includes a
wide variety of domains such as OS interaction, hardware design, high performance data
structures and algorithms, and testing methodologies.</p>

<p>But there&#8217;s a very bright silver lining. <em>I know of no better way to become a
better programmer than to study optimization</em>. The knowledge you pick up along
the way about topics you don&#8217;t encounter in your day to day work
will benefit you the rest of your career. You&#8217;ll write better
code, design more coherent systems, find and fixing bugs more quickly, and
perhaps most importantly, be able to think critically and reason about software
systems.</p>

<p>And now, we begin&#8230;</p>

<h3>Lesson 1: Building a Foundation</h3>

<p>To effectively optimize code across a variety of domains, you need to become a technical
renaissance wo/man. There&#8217;s no way around it: optimization takes at least a general understanding
of a <em>lot</em> of different areas of computing. Below are areas of particular interest.</p>

<h4>Hardware for Software People</h4>

<p>Many developers have an aversion to learning about hardware. Get over it. You&#8217;ll need a good
background in the topics below to be truly effective at low-level optimizations. All of them
are far too broad to cover adequately here. For the topic of caching, because of how often if affects
performance, I&#8217;ve included summaries of relevant information mostly aimed at refreshing the knowledge
of those already familiar.</p>

<h5>Memory</h5>

<h6>Recommended Reading</h6>

<p>The seminal modern work on Linux memory is surely libc maintainer Ulrich Drepper&#8217;s <a href="http://lwn.net/Articles/250967/">What Every Programmer Should Know About Memory</a>.  Honestly, There&#8217;s not much he doesn&#8217;t cover, so this is it for recommended readings.</p>

<h6>Cache architectures</h6>

<p>Modern CPUs have on die memory in order to facilitate caching, typically used to cache the contents of recently read or written values. The basis for singling out recently used values is the principal of <em>temporal locality</em> which states that, all things being equal, a resource used recently is likely to be needed again soon. Since access to system memory is comparatively expensive, caches operate not on individual addresses but &#8220;cache lines&#8221;, fixed size chunks of memory representing contiguous physical memory. Based on the idea of <em>spatial locality</em>, or that a resource physically close to one recently used will likely be used soon, caching memory in chunks has the added benefit that most programs access data reasonably sequentially. While the cache is meant to benefit programs without their needing to explicitly attempt to make use of it (or, indeed, even know of its existence), it can also play an adversarial role in low-level optimizations. Designing programs that work with the CPU&#8217;s cache is critical to good performance in highly optimized routines.</p>

<h6>Cache Coherence</h6>

<p>Multi-processor (and multi-core) architectures naturally require a consistent view of memory across all processors. Otherwise, threads running on different CPUs making a change to the same memory address could create an inconsistent state by setting their copy of the same element to different values. To compensate, CPU architectures implement <em>cache coherency protocols</em> using a variety of methods. Often, reading and writing have separate rules governing the actions that must be performed after the operation completes. The protocols differ not just between CPU manufacturers but between CPU families as well, making it somewhat difficult to make generalizations about &#8220;modern&#8221; cache coherency. That said, the information is widely available for most commercial processors and the implementation is usually based on one of a number of well-understood algorithms. When optimizing for memory access patterns, one must be mindful of how multiple threads on different CPUs operating on shared data can be <em>less</em> efficient than a single thread performing the same work because of cache coherency issues.</p>

<h6>False sharing</h6>

<p>Related to coherency, false sharing occurs when one thread writes and one or more threads read from logically separate areas of memory that happen to occupy the same cache line. These addresses in memory need not be related to one another in the host program (though their short distance usually means they are in some way). When the threads are running on the same core this is not a problem. When running on different cores, however, each write performed by one thread invalidates the cache line the readers are accessing. The effects of false sharing even on extremely simple programs can be dramatic. Herb Sutter has a great article <a href="http://www.drdobbs.com/go-parallel/parallel/eliminate-false-sharing/217500206">Eliminate False Sharing</a> that covers the topic with simple examples.</p>

<h6>Ping-Ponging</h6>

<p>When false sharing occurs with a frequently used memory location, the valid cache line will effectively bounce back and forth between the cores involved. This is known as &#8220;ping-ponging&#8221; or &#8220;thrashing&#8221;. Of course, ping-ponging need not be caused by false sharing. Any access pattern that results in multiple resources competing for the same cache line will exhibit this behavior.</p>

<h5>CPU</h5>

<ul>
<li>CPU pipeline</li>
<li>Instruction cache</li>
<li>Branch prediction</li>
<li>Logical versus physical cores (or why you&#8217;re dual core CPU reports more than two cores)</li>
<li>Extended instruction sets</li>
</ul>


<h5>Disk</h5>

<ul>
<li>Relative access speed</li>
</ul>


<h4>Know Your OS</h4>

<p>You should try to understand your target OS as intimately as possible. Different Linux kernel versions
can vary a great deal in implementation efficiency of both kernel and user space operations. For the same
reason, you should also be familiar with the particular version of the Linux distro you&#8217;re running.
A good way to learn about what&#8217;s slow in your kernel or Linux distro is to read the
change notes for all releases <em>after</em> the one you&#8217;re using. You&#8217;ll see bugs the developers
fixed as well as operations they optimized. In addition, they&#8217;ll normally have an
article or series of emails describing the change by first giving background as to why it&#8217;s slow. This
will help you anticipate possible sources of slowness.</p>

<p>The list below is a good overview of topics important to optimization in general.</p>

<h6>Virtual Memory</h6>

<ul>
<li>Implementation</li>
<li>Cache interaction</li>
</ul>


<h6>Atomic Operations</h6>

<ul>
<li>Implementation</li>
</ul>


<h6>Threading</h6>

<ul>
<li>Synchronization primitives</li>
<li>Context switching</li>
<li>Scheduling</li>
</ul>


<h6>User Space vs Kernel Operations</h6>

<ul>
<li>Affect on thread scheduling</li>
</ul>


<h6>IPC</h6>

<ul>
<li>System V vs POSIX shared memory</li>
<li>UNIX domain sockets</li>
<li>Memory mapped files</li>
<li>Implementations</li>
</ul>


<h3>Lesson 2: Wherein You Resist the Urge to Guess</h3>

<p>Ask any programmer what the slowest portion of their system is and they&#8217;ll likely mention a subsystem
with externally visible slowness. If you ask them <em>why</em> it&#8217;s slow, they&#8217;ll be happy to tell you the
exact portion of that subsystem&#8217;s code responsible for the slowness.</p>

<pre><code>They're almost certainly wrong
</code></pre>

<p>There is a key truth to be mindful of while doing optimization work: <em>programmers are, as a rule,
terrible at anticipating at the cause of slowness in their application.</em> This is counterintuitive but almost always
true. Time and time again developers will go off to &#8220;make something faster&#8221; without systematically <em>proving</em> the
cause of slowness and come back two weeks later with 700 lines of hand optimized code that have precisely <strong>zero</strong> impact
on overall performance. There&#8217;s a good reason for this, although it&#8217;s not an especially satisfying one: computers are complicated.
Even if you are aware of every cause of every performance issue ever, you&#8217;ll still have an extremely difficult time anticipating
the cause of slowness through reasoning alone. The interaction between the different subystems, logical units within those subsystems,
the operating system, the hardware, etc is just too complicated to be able to work out in your head. If it wasn&#8217;t, we would never
have performance issues or, more tellingly, bugs in our software.</p>

<h4>Families of Tools</h4>

<p>Luckily, you don&#8217;t have to rely on intuition when optimizing. There are scores of tools, both open and closed source, designed
to help developers find the reasons for a program&#8217;s slowness. They can generally be divided into a few classes of tools:</p>

<h5>Function Call Profilers</h5>

<p>Profilers are tools that create an <em>execution profile</em> of a running program. There are two general types of profilers: <em>statistical profilers</em> and <em>instrumenting profilers</em>. Statistical profilers are typically added in at link time and take &#8216;snapshots&#8217; of the executing program. These snapshots record the call stack of each thread of execution. Over time, the aggregate of these snapshots create a reasonably complete picture of the relative frequency of various operations (i.e. function calls). The other type of profiler interposes itself in some manner and records <em>every</em> function call instead of a sampling. This higher level of detail comes at a cost: your program will typically run <strong>noticably</strong> slower while being profiled.</p>

<h5>Cache profilers</h5>

<p>Cache profilers are used to determine the memory access patterns of a program and how effective it is at utilizing the CPU&#8217;s data cache. For each memory reference, the profiler will determine if the value was cached and at what cache level it was retrieved from. It also records cache misses, where the data must be retrieved from main memory.</p>

<p>Cache profilers are also usually capable of profiling instruction cache access as well. Similar to data cache, profilers typically record the count and source of cache hits and misses, as well as the cache level (if any) that eventually was found to contain the item in question.</p>

<p>Lastly, a number of cache profilers are able to profile <em>branch mispredictions</em>. When the CPU encounters a conditional branch in your code, like an if statement, it makes an (hopefully) informed guess as to which condition is more likely to be true. It can than prefetch the instructions for that branch of execution (or, depending on the architectures, multiple branches). In doing so, it avoids the need to wait until the CPU actually executes the conditional statement to fetch more instructions. Since CPU&#8217;s use <em>pipelining</em> to increase instruction throughput, waiting to see which conditional branch must be executed has a knock-on effect on subsequent instructions. If the CPU finishes executing a conditional instruction but the next instruction is not available (perhaps because the wrong branch was predicted), it must wait for the next set of instructions to be fetched, known as a <em>CPU stall</em>.</p>

<h5>Heap profilers</h5>

<p>Inevitably in your optimization journey you&#8217;ll come to realize a simple fact: dynamic allocation is <em>slow</em>. Really slow. You&#8217;ll look at the profile output for a program and see all of the time being spent in &#8221;&#8217;malloc&#8221;&#8217; and &#8221;&#8217;free&#8221;&#8217; Enter heap profilers. Rather than telling you how much <em>time</em> a portion of your code is taking, a heap profiler will tell you how much memory that portion is allocating. Many times, especially in enterprise development (for a reason I still don&#8217;t really understand), objects are allocated on the heap, used as local variables, and destroyed without passing ownership elsewhere. This is both unnessecary and wasteful. Stack objects are created statically and accessed via an offset from the stack pointer. Using them is as close to &#8220;free&#8221; as you&#8217;re going to get. Heap allocations are another thing altogether. You need to fetch a portion of memory from the OS which, as we discussed in describing cache profilers, is not always a lightening fast operation. Adding in virtual memory operations and the overhead of system calls in general and you&#8217;ve got one <em>slow</em> operation for zero benefit. Also, physical memory is a shared resource, so you better be sure you free it lest you create a memory leak and slow down or crash the machine.</p>

<h4>List of Profilers</h4>

<p>Below are links to some profilers for Linux systems. The valgrind suite is usually my go-to set of profiling tools. That said, I&#8217;ve
personally used almost every tool on the list. All are helpful in some way.</p>

<ol>
<li><a href="http://www.valgrind.org">Valgrind</a></li>
<li>oprofile: part of the Linux kernel. Check your distro to determine how to install.</li>
<li><a href="http://software.intel.com/en-us/articles/intel-vtune-amplifier-xe/">VTune</a>, Intel&#8217;s profiler for Intel CPUs</li>
<li><a href="http://developer.amd.com/tools/CodeAnalyst/Pages/default.aspx">CodAnalyst</a> AMD&#8217;s profiler for AMD CPUs</li>
<li><a href="http://en.wikipedia.org/wiki/Gprof">gprof</a> The GNU profiler, part of GNU binutils</li>
<li><a href="http://code.google.com/p/gperftools/">Google PerfTools</a> Now maintained outside of Google and renamed &#8216;gperftools&#8217;.</li>
</ol>


<p><em>This brings us to the end of Part 1 of the series. Part 2 gets into the meat of how to approach software optimization. Look for
here it next week.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python's Hardest Problem]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/03/31/pythons-hardest-problem/"/>
    <updated>2012-03-31T08:03:00-04:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/03/31/pythons-hardest-problem</id>
    <content type="html"><![CDATA[<p><em>For more than a decade, no single issue has caused more frustration or
curiousity for Python novices and experts alike than the Global
Interpreter Lock.</em></p>

<h2>An Open Question</h2>

<p>Every field has one. A problem that has been written off as too difficult, too time consuming. Merely mentioning an attempt to solve it raises eyebrows. Long after the community at large has moved on, it is taken up by those on the fringe. Attempts by novices are undertaken for no other reason than the difficulty of the problem and the imagined accolades that would accompany a solution. The open question in Computer Science of whether P = NP is such a problem. An answer to the affirmitive has the possibility to literally change the world, provided a &#8220;reasonable&#8221; polynomial time algorithm is presented. Python&#8217;s hardest problem is less difficult than crafting a proof of P = NP, to be sure. Nevertheless, it has not received a satisfactory solution to date, and the practical implications of a solution would be similarly transformative. Thus, it&#8217;s easy to see why so many in the Python community are interested in an answer to the question: &#8220;What can be done about the Global Interpreter Lock?&#8221;</p>

<!--more-->


<h2>A Low Level Look at Python</h2>

<p>To understand the GIL and its implications, we must start at Python&#8217;s foundations. Languages like C++ are compiled languages, so named because a program is fed in to a compiler where it is parsed according to the language&#8217;s grammar, transformed into a language agnostic intermediate representation, and linked into an executable comprised of highly optimized machine code. The compiler is able to optimize the code so aggresively because it is seeing the whole program (or large, self-contained chunks) at once. This allows it to reason about interactions between different language constructs and make informed decisions about optimization.</p>

<p>In contrast, Python is an interpreted language. The program is fed into an <em>interpreter</em> in order to be run. The interpreter has no knowledge of the program before it is run; rather, it knows the rules of Python and is capable of dynamically applying those rules. It too has optimizations, but optimizations of a rather different class. Since the interpreter cannot reason about the program proper, most of Python&#8217;s optimizations are optimizations of the interpreter itself. A faster interpreter means faster program execution &#8220;for free&#8221;. That is, when the interpreter is optimized, Python programs need not change to realize the benefit.</p>

<p>This is an important point, so it bears repeating. The execution speed of a Python program, all other things being equal, is directly tied to the &#8220;speed&#8221; of the interpreter. No matter how much optimization you do within your program itself, your program&#8217;s execution speed is still tied to how efficiently the interpreter can execute your code. It is clear, then, why much work has been devoted to optimizing the Python interpreter. It is the closest thing to a free lunch Python programmers can get.</p>

<h2>The Free Lunch Is Over</h2>

<p>Or is it? A generation of programmers have learned to write code while Moore&#8217;s Law was delivering hardware based speedups with predictable timing. If one wrote code that was slow, simply waiting a bit for faster processors was oftentimes the easiest solution. Indeed, Moore&#8217;s law still holds true and likely will for quite a bit longer, but the <em>way</em> in which it holds has fundamentally changed. No longer are clock rates steadily increasing to dizzying speeds. Instead, <em>multiple cores</em> are used to take advantage of tranistor density increases. Programs wishing to capitalize on new processors must be rewritten to exploit <em>parallelism</em>.</p>

<p>When most developers hear &#8220;parallelism&#8221; the immediately think of multithreaded programs. Utilizing multiple threads of execution is by far the most common way to take advantage of multicore systems. While mulit-threaded programming is a good deal tougher than &#8220;sequential&#8221; programming, the careful programmer may nevertheless exploit parallelizable portions of his or her code to great effect. The implementation language should be an afterthought, since almost all heavily used modern languages support multithreaded programming.</p>

<h2>A Surprising Fact</h2>

<p>Now we come to the crux of the issue. To take advantage of multicore
systems, Python must support multiple threads of execution. Being an
interpreted language, Python&#8217;s <em>interpreter</em> must be written in such a way
so that doing so is both safe and performant. We all know the issues
that multithreaded programming can present. The interpreter must be
mindful not to operate on internally shared data from different threads.
It must also manage user&#8217;s threads in such a way that the maximum amount of
computation is being performed at all times.</p>

<p>What, then, is the mechanism by which data is protected from
simultaneous access by different threads? The <em>Global Interpreter Lock</em>.
The name is instructive. Quite literally, it is a global (in the sense
of the interpreter) lock (in the sense of a mutex or simmilar construct)
on the interpreter. This approach is certainly safe, but it has (for the
new Python programmer), a startling implication: in any Python program,
no matter how many threads and how many processors are present, <em>only
one thread is being executed at any time</em>.</p>

<p>Many discover this fact by accident. Newsgroups and message boards are
littered with messages from Python novices and experts alike asking &#8220;why
does my newly multithreaded Python program run slower than when it had
only one thread?&#8221; Many feel silly even asking the question, since of course a
program with two threads where before there was just one will be faster
(assuming that the work is indeed parallelizable). In fact, the question
is asked so frequently that Python experts have crafted a standard
answer: &#8220;Do not use multiple threads. Use multiple processes.&#8221; But this
answer is even more confusing than its question. I shouldn&#8217;t use
multiple threads in Python? How can multithreading in a language as
popular as Python be so broken as to have experts recommending against
its use? Surely I&#8217;m missing something?</p>

<p>Sadly, nothing has been missed. Due to the design of the Python
interpreter, using multiple threads to increase performance is at best a
difficult task. At worst, it will <em>decrease</em> (sometimes signifcantly)
the speed of your program. A freshman CS undergrad could tell you what
to expect when threads are all competing for a single shared resource.
The results are often not pretty. That said, there are many times that
mulithreading works well, and it is perhaps a testament to both the
interpreter implementation and the core developers that there are not more complaints
about Python&#8217;s multithreading performance.</p>

<h2>What Now? Panic?</h2>

<p>So what, then, can be done? Are we as Python developers meant to give up
the idea of using multiple threads to exploit parallelism? Why does the
GIL need to guarantee only one thread is running at a time anyway?
Couldn&#8217;t finer-grained locks be added to protect individual objects from
simultaneous access? And why has no one attempted something like this
before?</p>

<p>These are useful questions with interesting answers. The GIL protects access to things like the current thread state and heap allocated object for garbage collection. There is nothing special about the Python language, however, that <em>requires</em> the use of a GIL. It is an artifact of the implementation. There are alternative Python interpreters (and compilers) that do not make use of a GIL. For CPython, though, it&#8217;s been there pretty much since the begining.</p>

<p>So why not get rid of it? Many are not aware, but this was attempted back in 1999 for Python 1.5 in the oft-cited but poorly understood &#8220;free threading&#8221; patches from Greg Stein. In the patches, the GIL was completely removed and replaced with finer grained locking. Its removal, however, came at the expense of execution speed for single-threaded programs. It was perhaps 40% slower when running with a single thread. Two threads showed an increase in speed, but beyond that the benefits did not scale linearly with the number of cores. Because of the degredation in execution speed, the patches were rejected and largely forgotten.</p>

<h2>The GIL is Hard. Let&#8217;s Go Shopping!</h2>

<p>The &#8220;free threading&#8221; patches are instructive, though, in that they demonstrate a fundamental point about the Python interpreter: removing the GIL is <em>hard</em>. Since the time of the patches, the interpreter has come to rely on <em>more</em> global state, making the removal of today&#8217;s GIL that much more difficult. It should be noted that it is precisely for this reason that many become interested in attempting to remove the GIL in the first place; hard problems are fun.</p>

<p>But perhaps this is all a bit misguided. Let&#8217;s consider what would happen if we had a magical patch that removed the GIL with no performance penalty to single threaded Python code. We would have what we said we wanted all along: a threading API that properly makes use of all processors simultaneously. Now that we&#8217;ve got what we want, is it actually a good thing?</p>

<p>Thread based programming is hard. There are no two ways about it. Every time one thinks he or she understands everything there is to know about how threading works, a new wrinkle is uncovered. A number of high-profile language designers and researchers have come out against the threading model because it is simply too difficult to get right with any reasonable degree of consistency. As anyone who has written a multithreaded application can tell you, both developing and debugging are exponentially more difficult compared to a single threaded program.  The programmer&#8217;s mental model, while well suited for sequential programs, just doesn&#8217;t match the parallel execution model. The GIL, then, unintentionally serves to help protect a programmer from his or her self. While synchronization primitives are still required when using threads, the GIL actually helps preserve consistency of data between threads.</p>

<p>It seems, then, that Python&#8217;s most difficult question may be asking the wrong thing. There&#8217;s a good reason that Python experts recommend using multiple processes instead of multiple threads, and it&#8217;s not to hide the inadequacies of the Python threading implementation. Rather, it is to encourage developers to use a safer and more straightforward concurrency model and reserve multithreaded programming for when it is absolutely necessary. To many, it is not clear what, if any, is the &#8220;best&#8221; model for parallel programming. What is clear to most, however, is multiple threads is not it.</p>

<p>As for the GIL, don&#8217;t think it just sits there static and unanalyzed.  Python 3.2 saw a new GIL implementation by Antoine Pitrou with encouraging results. It was the first major change to the GIL since 1992. The change is too large to explain here, but at a high level, the old GIL counted Python instructions to determine when it was time to give up the GIL. As it turns out, a single Python instruction can comprise a large amount of work, as they don&#8217;t translate 1:1 to machine instructions. In the new GIL, a hard timeout is used to instruct the current thread to give up the lock. When a second thread requests the lock, the thread currently holding it is compelled to release it after 5ms (that is, it checks if it needs to release it every 5ms). This leads to more predictable switching between threads when work is available.</p>

<p>It is not a perfect change, however. Perhaps the most active researcher into the effect of the GIL on various types of work is David Beazley. In addition to what is likely the most in-depth look at the pre-3.2 GIL, he has researched the new GIL implementation and discovered a number of interesting program profiles for which even the new GIL performs quite poorly. He continues to drive the discussion surrounding the GIL forward with practical research and published results.</p>

<p>Regardless of one&#8217;s personal feelings about Python&#8217;s Global Interpreter Lock, it remains the language&#8217;s most difficult technical challenge. To understand its implications requires a thorough understanding of operating system design, multithreaded programming, C, interpreter design, and the CPython interpreter implementation. Those prerequisites alone preclude many developers from investigating it more thoroughly.  Nevertheless, the GIL shows no signs of going away any time soon.  For the time being, it will continue to both confuse and surprise those new to the language while simultaneously intriguing those interested in trying to solve very difficult technical problems.</p>

<p><em>The preceeding is based on my research to date into the Python interpreter. While there are many other parts of the interpreter I hope to write about, none is more well known than the Global Interpreter Lock. The technical details were researched thoroughly against the CPython repository tip, though I imagine there are some inaccuracies.  If you spot one, please let me know so that I may correct it as quickly as possible.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[From Memcached to Redis to Surpdb]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/03/05/from-redis-to-memcached-to-surpdb/"/>
    <updated>2012-03-05T02:21:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/03/05/from-redis-to-memcached-to-surpdb</id>
    <content type="html"><![CDATA[<p>In this post, I&#8217;ll describe my journey to find the perfect caching solution for my Django-based site <a href="http://www.linkrdr.com">linkrdr</a>.  After trying Memcached and Redis, I settled on <strong>surpdb</strong>. I guarantee you haven&#8217;t heard of surpdb before, because I just finished writing it.</p>

<!--more-->


<p>Querying and retrieving large datasets is not the Django ORM&#8217;s sweet-spot. There are a number of reasons why Django&#8217;s QuerySets struggle with large amounts of data, but the primary reason is <em>because it wasn&#8217;t designed to work in that way</em>. For linkrdr, retrieving and analyzing a user&#8217;s data became too much for all previous attempts at marrying Django QuerySets with some form of caching. Caching in Memcached to avoid going to the database on subsequent calls worked well except in one regard: the first request took so long that it would time out, resulting in a user never being able to see their data.</p>

<p>Enter Redis. Current sweetheart of the NoSQL movement, Redis is a key-value store that resides entirely in resident memory. In addition to simple strings, values can take the form of a number of Redis&#8217;s native types: list, set, hash, etc. Redis is able to optimize on space for a number of these types, though there still is (sometimes significant) overhead for storing large numbers of small objects.</p>

<p>Installing Redis was easy. I headed over to the <a href="http://redis.io/">Redis site</a> and followed the installation instructions.  Since it&#8217;s written in C, it requires a quick compilation (so make sure you have gcc installed) and you&#8217;re ready to go. I changed the default <code>redis.conf</code> in the top-level directory and set <code>daemonize yes</code> so that redis would run in daemon mode. After that, a simple <code>./src/redis-server redis.conf</code> started a new redis daemon listening on the default ports.</p>

<p>But how was I going to make Redis any more useful than Memcached? I needed to rethink my entire strategy when it came to structuring my data. The Django ORM encourages good database normalization. Usually, this is helpful for all the reasons that database normalization is a <em>good thing</em>. Because of this, however, determining the links a user should see in their list of links to read required joining across four very large tables and returning a hierarchy of objects three levels deep.</p>

<p>I took a deep breath and began to rethink my data strategy. While the normalized structure was useful for inserting and updating records, <em>it poorly modeled the data I actually needed to return to the user.</em> I decided that I would create a new type of object which would live only in the Redis cache. It was a denormalized version of my <code>Link</code> model that additionally contained all of the fields from other models needed to display the data to the user. In this way, I would be querying Redis (not my Postgresql database) for an object that already had all of the data I needed. To the <code>Link</code> model I added a <code>to_dict()</code> function that returned a dictionary of the data I needed. This was saved directly in a Redis <code>hash</code> object using the <code>Link</code>&#8217;s id as the primary key.</p>

<p>Even then, however, I wasn&#8217;t done. Redis was taking about 350MB to store my 560,000 Links. Since I use a <a href="http://www.linode.com/?r=ae1808f234f8e219de24842336fada09ef81d52f">Linode server</a>, for which physical memory is always at a premium, to host linkrdr, this was less than ideal. When I looked at the size of Redis&#8217;s backup file, I was dismayed to see it was only 163MB. This meant that over 50% of the space needed to store my data was Redis overhead, since if it can be stored in a 163MB file it can theoretically be stored in memory using that amount of space. Some back-of-the-envelope calculations showed even 163MB was far more space than my data should require. I should make one thing very clear: this isn&#8217;t Redis&#8217;s fault. Though I tried my best to optimize my data structure according to the Redis optimization guidelines, Redis was not designed from scratch to store and retrieve <em>my</em> data structure as efficiently as possible.</p>

<p>But what if something <em>was</em> designed from the ground up to store my data structure? I may only be a journeyman web programmer, but I&#8217;ve been dealing with these types of design issues in C and C++ for my entire professional life. Having previously optimized a Django view using C++, I was comfortable with the interaction between Python and C++. I decided I would write my own NoSQL db according to <em>my</em> requirements. And surpdb was born.</p>

<p>surpdb (<strong>SU</strong>per <strong>R</strong>eliable <strong>P</strong>ython <strong>D</strong>ata<strong>B</strong>ase) was built with a single goal in mind: minimize both retrieval time and memory usage for <em>my</em> data. Since I was only supporting storing data from Python, I could specialize the internal data structures to store Python objects rather than some abstract type. In addition, since I knew the surpdb instance would be running on the same machine as the Python code querying it, I could use shared memory for communication. This was attractive for a number of reasons. With shared memory, I didn&#8217;t have to pay the cost associated with serializing an object, sending it over the wire, and deserializing and storing it. Rather, the Python process would store the object in a shared memory queue that surpdb would be watching. surpdb would then pick up the message and store it directly as a native Python object in its own shared memory datastore. Using shared memory both for storage and communication also meant that I didn&#8217;t need to give much thought to data backup. Since shared memory segments in Linux are represented as memory mapped files with a lifetime outside of that of the process that created them, the kernel would be responsible for asynchronously flushing my data to disk. In the event that surpdb crashed, recovery would be almost instantaneous as the snapshot of the database&#8217;s address space before the crash was sitting there waiting to be attached to.</p>

<p>In surpdb, lookups are O(1) as one would expect. There is <em>very</em> little overhead for storing objects. In fact, due to the fact that I&#8217;m working with my own data, surpdb actually stores objects in <em>less</em> space than they would take in memory on their own. Since I know most of my data structure is storing different URLs, I&#8217;m able to precache lookup tables of common substrings and simply store an index on the object in memory. This saves a <em>drastic</em> amount of space. I was able to store my 560,000 Link objects in only <em>13MB</em>. That&#8217;s an order of magnitude gain on Redis by specializing for my data. More importantly, it means the site can grow quite large without me needing by upgrade my Linode with more RAM.</p>

<h2>Update: Some Technical Details</h2>

<p>A number of people have asked what data structure I&#8217;m using for hashing.  The answer: none. As of an hour ago (when I realized I could do this), I removed the vector of pointers I was using and now rely on the integer key&#8217;s value as an offset into shared memory (since my allocator guarantees all allocations are in contiguous memory). String storage is aggresively optimized (again, for my data). Domain names are stored in a separate table and the remaining portion of the string is compressed. Non-url strings are stored using LZMA compression. The obvious speed tradeoff here was acceptable to me as I&#8217;m not responsing to thousands of requests a second.</p>

<p>The end result of all of this is that I finally have a caching solution that meets my needs. Pages are dynamically generated in under a second even for thousands of links. I don&#8217;t have to worry about more data requiring a machine upgrade (at least, not for a <em>very</em> long time). Also, I don&#8217;t have to worry about upgrades, support, or learning the tricks of a new cache. I&#8217;m intimately familiar with the inner workings of surpdb (which make sense since I wrote it) and can optimize as I go. Lastly and most importantly, I no longer have to worry about the linkrdr infrastructure and can focus on improving the user experience.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Single Founder SEO: Building Your Personal Brand]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/29/single-founder-seo-building-your-personal-brand/"/>
    <updated>2012-02-29T06:10:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/29/single-founder-seo-building-your-personal-brand</id>
    <content type="html"><![CDATA[<p>As a single founder, I realize I am at a tremendous disadvantage when it comes to non-technical work. There are only so many hours in a day, and I have a full-time job. Work on <a href="http://www.linkrdr.com">linkrdr</a>, therefore, must be prioritized. With so many interesting technical challenges to solve, a number of other useful activities fall by the wayside. Marketing is a big one. So how do I focus my efforts? <strong>By building my personal brand.</strong></p>

<!--more-->


<p>In a perfect world, I&#8217;d be part of a multi-person team working on the site full-time. A large portion of <em>someone&#8217;s</em> time would be devoted to getting the word out about linkrdr, improving the copy on our pages, and making sure we were doing everything right when it came to converting users. Since I can&#8217;t devote a ton of time to those activities without sacrificing the core experience of linkrdr, I have to be smart about how I <em>do</em> spend my time marketing.</p>

<p>As it turns out, I do very little real &#8220;marketing&#8221; for the site.  Instead, I&#8217;m focused on a slightly different strategy which, I hope, will pay dividends in the long run regardless of whether or not linkrdr is a success. <em>I&#8217;m building my personal brand.</em> Though it may sound slimy or silly, it&#8217;s really just the process by which you get your name &#8220;out there&#8221; and attached to things that people find useful.</p>

<p>For me, one obvious way to build my brand is through this blog. Don&#8217;t misunderstand: the blog was not started as a way to drive traffic anywhere. Rather, I started the blog because I felt that I had <em>taken</em> more from the technology community than I had <em>given</em>. It was my way of giving back.  That said, it has turned out to be a rather good tool for generating traffic, though not directly. The most traffic linkrdr has received was through others finding my blog and posting about it. <a href="http://en.wikipedia.org/wiki/Dave_Winer">Dave Winer</a> found the blog through a Hacker News post which with I had nothing to do. Between the Hacker News post and his Tweet of linkrdr, 700 users signed up in one day. Even though I didn&#8217;t cause this directly, I had positioned myself well for something like this to happen.</p>

<p>When I blog about programming related topics, I&#8217;ll usually post them to proggit or Hacker News, depending on the content. I&#8217;m not spamming every day with off-topic content (I hope). I&#8217;m just letting people know, &#8220;Hey, I wrote about this technical topic you might find interesting&#8221;. Like all things, some posts take off and drive thousands of visitors to the site while others are merely blips on the radar. With every post, though, I&#8217;m reaching more people. The more people I reach, the more chance I have of reaching <em>influencers</em>.</p>

<p>A word of advice: do not start a <em>personal</em> blog simply to drive traffic somewhere else. Most times, it will be transparent and turn people off. Remember, your name is attached to this, for better or worse. On the other hand, it&#8217;s quite customary to build a blog for your site overflowing with link-bait content. I think for the most part this is accepted practice now, though I choose to reserve the blog space on linkrdr for messages to users.</p>

<p>While blogging is a fantastic way to build your personal brand, it is certainly not the only way. Becoming active on StackOverflow serves two purposes: you get a chance to give back to the technology community at large and you begin to establish yourself as a domain expert (hopefully). I&#8217;ve found contributing to Stack Overflow to be rewarding even though it doesn&#8217;t directly drive traffic to the site. At the very least it&#8217;s another part of your personal portfolio that establishes your technical credibility.</p>

<p>Contributing to open source projects or creating your own is similarly helpful. <a href="http://www.kalzumeus.com">Patrick McKenzie</a>, whom Hacker News readers probably better recognize as <strong>patio11</strong>, created a dialogue with other developers in creating A/Bingo, the Ruby A/B testing software grown from his BingoCardCreator site. Probably the best <em>recent</em> example of personal brand building, Patrick went from Japanese salary-man to self-sufficient entrepreneur through a (seemingly, but not definitely) long, targeted campaign at getting his name out there. It worked, and he now consults professionally in addition to running a number of websites.  Open source software starts the conversation with others. Especially if your project is technology related, throwing it on GitHub can rarely hurt.</p>

<p>One side note: on all the sites I contribute to, I do so under the same username, jknupp. This is done purposely. What good is building your personal brand when you&#8217;re doing it as NinjaPirate14? Use your real name or some variation thereof. It will have the adding benefit of stopping you from submitting something you wouldn&#8217;t want your name attached to, which probably shouldn&#8217;t be posted in the first place.</p>

<p>linkrdr is still in its infancy, having only begun two and a half weeks ago, but it already has a good number of users. Almost all of them found the site through finding <em>me</em>. Building your brand as a single founder may be the most time effective form of SEO available. It&#8217;s certainly a good thing to do regardless, as you never know where opportunities will come from.</p>

<p>Questions or comments on <em>Single Founder SEO: Bulding Your Personal Brand</em>? Let me know below or email me at <a href="mailto:jknupp@gmail.com">jknupp@gmail.com</a>. Also, <a href="http://www.twitter.com/jeffknupp/">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Django Memcached: Optimizing Django Through Caching]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/24/django-memcached-optimizing-django-through-caching/"/>
    <updated>2012-02-24T09:00:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/24/django-memcached-optimizing-django-through-caching</id>
    <content type="html"><![CDATA[<p>Caching is a subject near and dear to the heart of many
peformance-minded programmers. For those coming to web programming
without other programming experience, caching may be a new topic. For
programmers new to the web, using an external cache may be an approach
not yet considered. In this post, I&#8217;ll describe how, through the use of Django&#8217;s caching support, I was able to <strong>reduce <a href="http://www.linkrdr.com">linkrdr&#8217;s</a> page load time from over 3.5 seconds to 0.01 seconds.</strong></p>

<!--more-->


<h2>What is Caching?</h2>

<p>Caching is a word that changes meaning a bit depending on the context in which it&#8217;s used, but in the general sense, <em>caching is the process by which the result of previous computation is saved and reused without re-performing the computation.</em> In the Django specific sense, there are three different types of caching:</p>

<ol>
<li><p><strong>The per-site cache</strong>: Saves the result of requests to all URLs
for reuse when a request for the same URL is later made.</p></li>
<li><p><strong>The per-view cache</strong>: Saves the result of requests resolving to
specified views for reuse when a request resolving to the same
view is made.</p></li>
<li><p><strong>The low-level cache API</strong>: Used by the developer to set, retrieve, and maintain objects in the cache manually.</p></li>
</ol>


<p>While the first two methods are certainly useful for some sites, the third is the most interesting. Caching requires some backend cache (obviously), and Django ships with a few out of the box. It can keep the cache in memory (not particularly useful when new threads are spawned for HTTP requests by the HTTP server), in the database (fine but slow), or on the filesystem (ditto).</p>

<p>Then there&#8217;s <a href="http://memcached.org">Memcached</a>. Memcached is pretty well known in the web development community as an extremely flexible, scalable, and resilient external caching solution. The fact that Django ships with a &#8220;low-level&#8221; API for interacting with Memcached is great, although it does require the installation of a Python/Memcached interface package, of which there are two: python-memcached and pylibmc. Let&#8217;s investigate using Memcached via a case study.</p>

<h2>Case Study: linkrdr.com Page Load Time Optimization</h2>

<p>I&#8217;ve talked about <a href="http://www.linkrdr.com">linkrdr&#8217;s</a> optimization
techniques before. The main view shows links from entries in a
user&#8217;s subscribed feeds. These links have been aggregated and sorted according to a ranking algorithm. For example, if a user subscribes to 10 RSS feeds and follows a few Twitter users and 4 of those sources mention a particular link, that link should appear higher in your list of links to read than a link from a single feed entry.</p>

<p>Retrieving, analyzing, aggregating, and sorting all of the links from all of the entries from all of a user&#8217;s subscribed feeds is computationally expensive. The calculation of a link&#8217;s &#8220;importance&#8221; was optimized by <a href="http://www.jeffknupp.com/blog/2012/02/15/optimizing-django-views-with-c-plus-plus/">rewriting the calculation in C++ and calling it from the view</a>. The database query <a href="http://www.jeffknupp.com/blog/2012/02/14/profiling-django-applications/">was similarly optimized</a>. These proved not to be enough, however, in the face of a flood of new users (and new data) to linkrdr.</p>

<p>3.5 seconds. That was how long it took to generate the data within the
main view function. Previously, it had been under a second, but after a
sudden flood of users and data, things had gotten out of control. I knew that I needed to implement caching to cut down page load time, but there were a few wrinkles. First, the datasets linkrdr returns are rather large, even with pagingation reducing the items shown to 100 per page. Second, a link had two real scores: one that could be calculated just by inspecting the link&#8217;s properties in isolation and one that could only be calculated with respect to <strong>all</strong> the other links in a user&#8217;s feed. These issues combined led to an interesting optimization problem.</p>

<p>The first goal was to cache all the user&#8217;s sorted links whenver a
request came in, to be used in subsequent requests. I originally tried
to cache the entire result set like so:</p>

<figure class='code'><figcaption><span>Caching the results  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
</span><span class='line'>    <span class="n">results</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</span><span class='line'>    <span class="k">if</span> <span class="ow">not</span> <span class="n">results</span><span class="p">:</span>
</span><span class='line'>        <span class="n">results</span> <span class="o">=</span> <span class="n">do_a_ton_of_work</span><span class="p">()</span>
</span><span class='line'>        <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span>
</span><span class='line'>    <span class="c"># ...</span>
</span></code></pre></td></tr></table></div></figure>


<p>Each time I tried this the results weren&#8217;t added to the cache. After about 15 minutes of digging, I realized that the dataset was larger than memcached&#8217;s limit for record sizes. When that happens, the call to <code>cache.set()</code> (maddeningly) fails silently.</p>

<p>So I couldn&#8217;t cache the whole thing, but this turned out to be a useful
exercise. I realized I didn&#8217;t need to cache the entire set as one big value. I could chunk the dataset in the same size chunks as were being paginated (currently 100 links). So now, the code looks like this:</p>

<figure class='code'><figcaption><span>Caching chunks  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
</span><span class='line'>    <span class="n">page</span> <span class="o">=</span> <span class="n">get_page</span><span class="p">(</span><span class="n">request</span><span class="p">)</span> <span class="c"># for pagination</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">results</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</span><span class='line'>    <span class="k">if</span> <span class="ow">not</span> <span class="n">results</span><span class="p">:</span>
</span><span class='line'>        <span class="n">results</span> <span class="o">=</span> <span class="n">do_a_ton_of_work</span><span class="p">()</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
</span><span class='line'>            <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">results</span><span class="p">[</span><span class="n">index</span><span class="p">:</span><span class="n">index</span><span class="o">+</span><span class="mi">99</span><span class="p">])</span>
</span><span class='line'>    <span class="c"># ...</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Cache Eviction</h2>

<p>One thing to remember is that caches are not some magical never-ending source of storage. Memcached stores items in memory, of which it has a limited supply (limited by you, that is). When a cache is using the full amount of memory allotted and gets a request to add something new, a choice has to be made. This choice is known as the cache&#8217;s <em>eviction policy</em>, since a record is about to be &#8216;evicted&#8217; from the cache. Memached uses a variant of LRU, or Least Recently Used, eviction. Glossing over the topic of page allocation and sizing, which you can read about on Memcached&#8217;s wiki, the cache looks for the least recently used item and overwrites it with the new value. This approach has good <em>temporal locality</em>, since something that was used recently (especially in web programming), is likely to be used again soon. Things not used for a while are less likely to be used again soon, and thus are good candidates to remove from the cache. For linkrdr, this has a few useful side effects. The view&#8217;s cached items are likely to be used soon after they are created (as a user browses their links) and then not used at all (when they leave the site), which perfectly matches the cache eviction policy. Also, using small chunks instead of the whole dataset allows eviction with more granularity, so a user&#8217;s entire cache isn&#8217;t lost all at once.</p>

<h2>Which is Nice, Except&#8230;</h2>

<p>But there are some problems with this approach. For one, the first (uncached) request still takes the full 3.5 seconds. The first request being the most important one, this is not ideal. Second, we have to deal with updates to the dataset that would require a recalculating of the scores of each of the links (for example, when a user adds a new feed or linkrdr is updating feed items). Using some additional features of Memcached, we can overcome these obstacles as well.</p>

<p>Let&#8217;s deal with updates to the dataset first. Django supports &#8220;versioning&#8221; of cache records. If you specify a version number in your <code>cache.set(key, value, version=my_version)</code> call, then a corresponding <code>cache.get(key, version=some_other_version)</code> call will not return any data. Using versioning, we can change things around and store the user&#8217;s current &#8216;version&#8217; in the cache. When we want to get the cached dataset, we specify the user&#8217;s cached version number. In this way, we are able to <em>invalidate</em> old cache entries without searching through the cache for all of a user&#8217;s cached items. An example will help clarify:</p>

<figure class='code'><figcaption><span>Memcached with versioning  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
</span><span class='line'>    <span class="n">version</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</span><span class='line'>    <span class="k">if</span> <span class="ow">not</span> <span class="n">version</span><span class="p">:</span>
</span><span class='line'>        <span class="n">version</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class='line'>        <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">version</span><span class="p">)</span>
</span><span class='line'>    <span class="n">page</span> <span class="o">=</span> <span class="n">get_page</span><span class="p">(</span><span class="n">request</span><span class="p">)</span> <span class="c"># for pagination</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">results</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="mi">100</span><span class="p">),</span> <span class="n">version</span><span class="o">=</span><span class="n">version</span><span class="p">)</span>
</span><span class='line'>    <span class="k">if</span> <span class="ow">not</span> <span class="n">results</span><span class="p">:</span>
</span><span class='line'>        <span class="n">results</span> <span class="o">=</span> <span class="n">do_a_ton_of_work</span><span class="p">()</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
</span><span class='line'>            <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">results</span><span class="p">[</span><span class="n">index</span><span class="p">:</span><span class="n">index</span><span class="o">+</span><span class="mi">99</span><span class="p">],</span> <span class="n">version</span><span class="o">=</span><span class="n">version</span><span class="p">)</span>
</span><span class='line'>    <span class="c"># ...</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, when a user adds a feed and the link scores need to be recalculated, we can simply increment his or her version so that the next <code>cache.get()</code> will be a cache miss.</p>

<p>But wait, I just said we <em>want</em> a cache miss. That can&#8217;t be right. What we&#8217;d <em>really</em> like is for the links to be recalculated <em>and cached</em> and the old values invalidated. To accomplish this without interrupting the user (remember recalculating takes a couple seconds), we fire off a Celery task to ansynchronously recalculate the results, update the cache, and update the user&#8217;s version. This way, the user can continue using the site and, if they take longer than 3-4 seconds between adding a feed and looking at their new links, we&#8217;ll have the results <em>prefetched</em>. The idea of prefetching is a powerful one, and it solves the other problem (the first visit to a page results in a cache miss) as well. When linkrdr updates the feeds, it also caches the results for frequent users of the site (which it determines using yet more cached data). This way, the people who use the site the most experience instant page loads. Infrequent users will experience at most one slow page load.</p>

<p>It would be nice if we could prefetch every user&#8217;s data after every update, but linkrdr has neither the memory nor computing power to do this. In a way, this is a good thing, because throwing more hardware at a problem doesn&#8217;t require much thought. Many of the interesting technical challenges linkrdr faces come about because of the constraints on memory and CPU availability. Since I&#8217;m running on a single VPS, I have to get a bit creative with some of my solutions. If I didn&#8217;t have to consider these things, the site would likely be worse for it and would certainly be less interesting to work on. The current caching solution can scale with the site without straining resources too much.</p>

<p>The preceeding is <a href="http://www.linkrdr.com">linkrdr</a>&#8217;s current approach to caching. One interesting side note: I&#8217;m currently investigating running memcached in a distributed manner using the other VPS I use to host <a href="http://www.illestrhyme.com">IllestRhyme</a>. Since the latter site has far more spare CPU cycles, computation can be partially offloaded to the second machine and the results stored in a distributed cache (which Memcached and Django helpfully support out of the box). Aditionally, sprinkling in other types of caching (like file based caching) may make it possible to prefetch all data for all users.</p>

<p>Questions or comments on <em>Django Memcached: Optimizing Django Through Caching</em>? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How linkrdr went semi-viral]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/21/how-linkrdr-went-semi-viral/"/>
    <updated>2012-02-21T04:34:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/21/how-linkrdr-went-semi-viral</id>
    <content type="html"><![CDATA[<p>I was a bit under the weather this past weekend, but it turns out I
wasn&#8217;t the only thing to go viral. Below is a brief story of how <a href="http://www.linkrdr.com">linkrdr</a> enjoyed it&#8217;s first encouter with virality.</p>

<h2>Background</h2>

<p>Before Saturday, linkrdr had about 10 users, who had figured out a way
to signup without me really providing one. Sometime Thursday evening, I
believe, I slapped a &#8216;Beta&#8217; sticker on the front page, cleaned some
stuff up, and declared linkrdr open for business. Come the weekend, I
was under the weather and not feeling like working on anything, so I
didn&#8217;t check any of my sites until Monday at 4pm. I cruised over to my
<a href="http://getclicky.com/66528953">Clicky</a> dashboard and took a look at the
stats for this blog. Then something caught my eye&#8230;</p>

<p><img src="http://66.228.46.113/static/img/linkrdr_growth.png" title="linkrdr visits per day" ></p>

<!--more-->


<h2>&#8220;Uh oh&#8221;</h2>

<p>The graph for linkrdr, which is usually totally flat, had suddenly
shot up almost vertically. I quickly checked the number of users via the
django console and felt a pit in my stomach: <strong>720 users had signed up
in the past 24 hours</strong>. I caught my breath, then checked how many total
links linkrdr was managing. I read the number three times. I couldn&#8217;t
believe it: <strong>109,214 links</strong> across about 3,700 feeds. I fired up my
browser to see if the site had melted down. To my surprise, it was
pretty responsive. After clicking around more and convincing myself the
server wasn&#8217;t on fire, I did a little <a href="http://getclicky.com/66528953">Clicky</a> style investigating.</p>

<p>It became clear rather quickly that most of my links were coming from
two sources: <a href="http://www.startupsea.com">startupsea.com</a>, a new
startup-roundup type site I hadn&#8217;t heard of, and
<a href="http://www.scripting.com">scripting.com</a>. When I saw the second site,
my heart skipped a beat. I&#8217;m very familiar with scripting.com, the blog
of <a href="http://en.wikipedia.org/wiki/Dave_Winer">Dave Winer</a>. I checked out
scripting.com and sitting there on his list of links was a link to
linkrdr. He had also tweeted about it to his <strong>75,000</strong> followers.
Between the two sites, linkrdr had gone mini-viral.</p>

<h2>Aftermath</h2>

<p>I quickly decided that I needed to bullet-proof the site (how I did so
will be the topic of my next post). I was proud
that the site could handle the drastic uptick in flow, but I wasn&#8217;t
going to leave anything to chance. Over the past 18 hours, I&#8217;ve been
adding features that users have been clamoring for (OPML import has been
added, for one), fixing bugs, and generally cleaning things up. It&#8217;s still too early to
tell if this was just a one-off blip, as the US public had Monday off of
work. Tuesday morning will be an interesting one. Let&#8217;s hope linkrdr
gets more viral-love!</p>

<p>Questions or comments on <em>How linkrdr Went Semi-Viral</em>? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Optimizing Django Views With C++]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/15/optimizing-django-views-with-c-plus-plus/"/>
    <updated>2012-02-15T09:55:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/15/optimizing-django-views-with-c-plus-plus</id>
    <content type="html"><![CDATA[<p>In my <a href="http://www.jeffknupp.com/blog/2012/02/14/profiling-django-applications/">previous post</a> I outlined the method by which one goes about profiling a Django application. I used a view from <a href="http://www.linkrdr.com">linkrdr</a> as an example. That view is responsible of aggregating, ranking, and sorting all of the links in a user&#8217;s feeds (RSS, atom, Twitter, etc). The code from the post was an early, simplistic implementation of the view. I have, however, a much more robust scoring algorithm, written in Python, which I planned to used on the site.</p>

<p>You may have caught the word &#8216;planned&#8217; in there. The algorithm turned out to be too slow. Rather, my Python implementation of the algorithm
was slower than what I deemed acceptable. After thinking of various architectural changes that could be made to solve the problem, I settled on a somewhat radical solution for a Django developer: <strong>I implemented the view in C++</strong>.</p>

<p>I realize that not every Django developer knows C++, nor should they, but those that do should realize it&#8217;s a viable tool available when Python is just too slow. Eventually, you may get to a point where you can&#8217;t really optimize your Python code any more. In this case, profiling will show that most of your time is spent in Python library calls. Once you hit that point, you&#8217;ve either written a horribly inefficient algorithm or you&#8217;ve got a problem not suited for Python.</p>

<p>When I realized I had hit that point with my view code, I panicked.
<em>&#8216;What more is there to do?&#8217;</em> I wondered. Then I rememberd a work
project where I had written some C++ code that interfaced with Python.
From a technical perspective, there was nothing stopping me from
implementing some aspects of my Django app in C++ (besides the fact
that it&#8217;s <em>excruciating</em> to write in coming from Python). Since linkrdr
is a single-person project, there are no teammates who need to grok the
code. I&#8217;m free to implement it as I wish.</p>

<!--more-->


<h2>Setting Up</h2>

<p>Having written &#8220;pure&#8221; C++/Python interoperability code before, and not
wanting to see <code>Py_XDecRef</code> again, I decided I would use boost::python. To begin, I made sure I had the latest <a href="http://www.boost.org">Boost</a>
libraries and a recent version of gcc installed so I could use C++11
features, which really are rather nice. After building the newest
version of the boost::python library, I set out to learn how to actually
use the thing. It turned out to be incredibly easy.</p>

<p>boost::python wraps a number of Python datatypes for you: <code>object</code>
represents a generic Python object, <code>list</code> is a list, and so on. Since
Python is dynamically typed, there really aren&#8217;t a whole lot of these.
&#8216;Everything is an Object&#8217; means that everything is a
boost::python::object and can be accessed in that way.</p>

<p>In addition to primitive and container type wrappers, boost provides a
clear and concise mechanism to make C++ classes and functions visible to Python. I had
a simple class in the code of my previous entry name <code>LinkScore</code>. It
was basically a C struct with a list of objects and an integer. The C++
code for it is:</p>

<figure class='code'><figcaption><span>A simple C++ class  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'><span class="k">using</span> <span class="k">namespace</span> <span class="n">boost</span><span class="o">::</span><span class="n">python</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">LinkScore</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="k">public</span><span class="o">:</span>
</span><span class='line'>        <span class="n">LinkScore</span><span class="p">()</span> <span class="p">{}</span>
</span><span class='line'>        <span class="n">LinkScore</span><span class="p">(</span><span class="k">const</span> <span class="n">object</span><span class="o">&amp;</span> <span class="n">link</span><span class="p">,</span> <span class="kt">int</span> <span class="n">score</span><span class="p">)</span> <span class="o">:</span> <span class="n">score_</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="n">links_</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">link</span><span class="p">);</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="n">list</span> <span class="n">links_</span><span class="p">;</span>
</span><span class='line'>    <span class="kt">int</span> <span class="n">score_</span><span class="p">;</span>
</span><span class='line'><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you&#8217;re thinking my data members should be private, guess what: I
don&#8217;t care. That&#8217;s part of the joy of working on code that only you will
use. You get to write it and use it however you want.</p>

<h2>The Details</h2>

<p>Anyway, the boost::python code to make this callable from Python is:</p>

<figure class='code'><figcaption><span>boost::python code for Python interoperability  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'>    <span class="n">class_</span><span class="o">&lt;</span><span class="n">LinkScore</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;LinkScore&quot;</span><span class="p">,</span> <span class="n">init</span><span class="o">&lt;</span><span class="n">object</span><span class="p">,</span> <span class="kt">int</span><span class="o">&gt;</span><span class="p">())</span>
</span><span class='line'>        <span class="p">.</span><span class="n">def_readwrite</span><span class="p">(</span><span class="s">&quot;links&quot;</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">LinkScore</span><span class="o">::</span><span class="n">links_</span><span class="p">)</span>
</span><span class='line'>        <span class="p">.</span><span class="n">def_readwrite</span><span class="p">(</span><span class="s">&quot;score&quot;</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">LinkScore</span><span class="o">::</span><span class="n">score_</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Really, it couldn&#8217;t be more simple. The <code>&lt;Python.h&gt;</code> way of
accomplishing this involves setting a struct with like 40 values to
declare each class. I was happy to not have to bother with that.</p>

<p>The actual code for my view is a free function called <code>get_scores</code>.
Here&#8217;s a brief snippet:</p>

<figure class='code'><figcaption><span>C++ code to be called by my Django view  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'><span class="k">using</span> <span class="k">namespace</span> <span class="n">boost</span><span class="o">::</span><span class="n">python</span><span class="p">;</span>
</span><span class='line'><span class="k">using</span> <span class="n">namspace</span> <span class="n">std</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">CompareObject</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">public</span><span class="o">:</span>
</span><span class='line'>      <span class="kt">bool</span>  <span class="k">operator</span><span class="p">()(</span><span class="k">const</span> <span class="n">LinkScore</span><span class="o">&amp;</span> <span class="n">l</span><span class="p">,</span> <span class="k">const</span> <span class="n">LinkScore</span><span class="o">&amp;</span> <span class="n">r</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">l</span><span class="p">.</span><span class="n">score_</span> <span class="o">&gt;</span> <span class="n">r</span><span class="p">.</span><span class="n">score_</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="p">};</span>
</span><span class='line'>
</span><span class='line'><span class="n">list</span> <span class="n">get_scores</span><span class="p">(</span><span class="n">object</span> <span class="n">links</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="n">object</span> <span class="n">utility</span> <span class="o">=</span> <span class="n">import</span><span class="p">(</span><span class="s">&quot;links.utility&quot;</span><span class="p">);</span>
</span><span class='line'>    <span class="n">set</span><span class="o">&lt;</span><span class="n">LinkScore</span><span class="p">,</span> <span class="n">CompareObject</span><span class="o">&gt;</span> <span class="n">seen_links</span><span class="p">;</span>
</span><span class='line'>    <span class="n">list</span> <span class="n">python_seen_links</span><span class="p">;</span>
</span><span class='line'>    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">len</span><span class="p">(</span><span class="n">links</span><span class="p">);</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="k">const</span> <span class="n">object</span><span class="o">&amp;</span> <span class="n">link</span> <span class="o">=</span> <span class="n">links</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span class='line'>        <span class="n">LinkScore</span> <span class="n">score</span> <span class="o">=</span> <span class="n">LinkScore</span><span class="p">(</span><span class="n">link</span><span class="p">,</span> <span class="n">score_link</span> <span class="p">(</span><span class="n">link</span><span class="p">,</span> <span class="n">links</span><span class="p">));</span>
</span><span class='line'>        <span class="k">auto</span> <span class="n">iter</span> <span class="o">=</span> <span class="n">seen_links</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">score</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">if</span> <span class="p">(</span><span class="n">iter</span> <span class="o">!=</span> <span class="n">seen_links</span><span class="p">.</span><span class="n">end</span><span class="p">())</span>
</span><span class='line'>        <span class="p">{</span>
</span><span class='line'>            <span class="c1">// Do stuff</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>        <span class="k">else</span>
</span><span class='line'>        <span class="p">{</span>
</span><span class='line'>            <span class="c1">// Do other stuff</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="c1">// TODO: Optimize this</span>
</span><span class='line'>    <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="n">i</span> <span class="o">=</span> <span class="n">seen_links</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">seen_links</span><span class="p">.</span><span class="n">end</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="n">python_seen_links</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">);</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">python_seen_links</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you know C++ and Python, it&#8217;s almost like reading a mix of the two.
The above, however, is valid C++ code and is the interface that Python
uses to call into my scoring library. To expose this function to Python,
all that&#8217;s needed is <code>def ("get_score", get_score);</code> within a
<code>BOOST_PYTHON_MODULE</code> block, which names the module to be imported.</p>

<p>When I was done writing the C++ code, I compiled it using gcc and Boost&#8217;s bjam build tool,
set my LD_LIBRARY_PATH to pickup libboost_python.so, and fired up a
shell from manage.py (well, a &#8216;shell_plus&#8217; really). I used the cProfile
module to compare the C++ version of the view with the Python version of
the view. The results were satisfying: an 8x speedup with the C++
version.</p>

<p>To call the C++ code, I just needed to make sure the .so generated was
on my PYTHON_PATH. I could then <code>import</code> it like a normal Python
library. I added it to my views.py and ran my unit tests. After they
passed, I committed everything and put the new code through it&#8217;s paces
on the development web server. The reponse time was noticably improved,
with the view being served seemingly instantaneously.</p>

<h2>Wrap Up</h2>

<p>I realize this is not an optimization option avaiable to everyone, but
it <em>is</em> an option. Python is a fantastic language and Django is a nice
framework. When you need raw speed for computationally expensive
procedures, though, nothing beats getting closer to the metal. Overall,
I&#8217;m quite happy with the results and how easy it was to implement. I
will refrain from writing any more C++ code for linkrdr unless
absolutely necessary. It&#8217;s nice to know, however, that the option is there.</p>

<p>Questions or comments on <em>Optimizing Django Views With C++</em> ? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp/">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Profiling Django Applications: A Journey From 1300 to 2 queries]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/14/profiling-django-applications/"/>
    <updated>2012-02-14T09:33:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/14/profiling-django-applications</id>
    <content type="html"><![CDATA[<p>In this post, I&#8217;ll discuss profiling Django applications through a case
study in <a href="http://www.linkrdr.com">linkrdr&#8217;s</a> code. Through the use of
profiling tools, I was able to reduce the number of database queries a
view was using from <strong>1300</strong> to 2.</p>

<h2>Introduction To Profiling</h2>

<p>At some point in most Django projects, some part of the application
becomes &#8216;slow&#8217;. This doesn&#8217;t have to be the case (more on that later),
but it&#8217;s often the result of changes made without performance
in mind.</p>

<p>In the begining, this is actually a good thing: <strong>focus on
making it work first, then focus on making it fast</strong>. Of course, you
don&#8217;t want to code yourself into a corner by writing code that &#8220;works&#8221;
but does so in a way that it will <em>never</em> be fast. Instead, you want to
keep performance in the back of your mind while implementing a solution
that makes sense.</p>

<p>Once you&#8217;ve proven your solution works through your automated tests
(<a href="http://www.jeffknupp.com/blog/2012/02/11/unit-testing-in-django/">You are using automated tests, right?</a>),
the next step is to make sure its performance is acceptable. Note that
I didn&#8217;t say &#8216;optimal&#8217;. <strong>Don&#8217;t waste time making something faster than
it needs to be</strong>. This should be common sense but, once the optimization
bug bites, it&#8217;s common for developers to go a bit off the deep end and
keep trying to find optimizations long after it&#8217;s necessary.</p>

<!--more-->


<p>So you&#8217;re solution works, but it&#8217;s slower than what you&#8217;ve deemed
acceptable. What&#8217;s the first step? For far too many developers, it&#8217;s</p>

<ol>
<li>Fire up my editor</li>
<li>Take a look around</li>
<li>Guess what I think is causing slowness</li>
<li>Make a bunch of changes</li>
<li>Hope it got faster</li>
</ol>


<p>Wrong, wrong, wrong. If you take away one thing from the post, let this
be it: <strong>developers are notoriously bad at predicting performance
bottlenecks</strong>. People think, &#8216;Well, I wrote it, so I should know what
could be causing slowness.&#8217; Instead of relying on faulty intuition, we should be relying on <em>data</em>.</p>

<p>Profiling is the process by which we accumulate data on the performance
of an application. This data can come in many forms, but usually is some
variation on reporting two things: the number of times a function or
line of code was executed and how much time it took to do so. For every modern
language there exist some form of profiling tools. Use them.</p>

<h2>A Case Study</h2>

<p><a href="http://www.linkrdr.com">linkrdr</a> allows, among other things, a user to
import their RSS/Atom/Twitter/Anything Else feeds and get an
inteligently laid out view of the <em>links</em> contained in their feeds. The
<code>show_items</code> view for linkrdr is responsible for retrieving the user&#8217;s
current feeds, gathering the links from those feeds&#8217; entries, and
scoring, sorting, and aggregating the links for presentation.</p>

<p>When I first began work on the view, I did so with a unit test prewritten.
I needed to get that test working, so I did so in the simplest way possible. Here&#8217;s what
the code looked like:</p>

<figure class='code'><figcaption><span>Intial show_items implementation  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">show_items</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
</span><span class='line'>    <span class="n">feeds</span> <span class="o">=</span> <span class="n">Feed</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">users__id</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</span><span class='line'>    <span class="n">seen_links</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">class</span> <span class="nc">LinkScore</span><span class="p">():</span>
</span><span class='line'>        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">link</span><span class="p">,</span> <span class="n">score</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">links</span> <span class="o">=</span> <span class="p">[</span><span class="n">link</span><span class="p">]</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">feed</span> <span class="ow">in</span> <span class="n">feeds</span><span class="p">:</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">feed</span><span class="o">.</span><span class="n">entry_set</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
</span><span class='line'>            <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">entry</span><span class="o">.</span><span class="n">link_set</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
</span><span class='line'>                <span class="c"># determine score for link</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">sorted_links</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">seen_links</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
</span><span class='line'>            <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">render_to_response</span><span class="p">(</span><span class="s">&#39;links/entries.html&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s">&#39;links&#39;</span><span class="p">:</span> <span class="n">sorted_links</span><span class="p">,</span> <span class="p">},</span> <span class="n">context_instance</span><span class="o">=</span><span class="n">RequestContext</span><span class="p">(</span><span class="n">request</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Simple, right? If someone asked you to write psuedo-code to perform this
task, I&#8217;m guessing it would look largely similar to this. Remember,
that&#8217;s a good thing in the begining. We&#8217;re focusing on correctness more
than performance.</p>

<p>This code turned out to be &#8216;all right&#8217; in the performance department.
It eventually got on my nerves, though, becuase I knew it has a problem that experienced Django developers probably
spotted right away. Even though I was %99.99 percent sure I knew what
was slowing down this view, I approached optimizing this code the same
way I approach any optimization task. I began with profiling.</p>

<p>Profiling in Django is a little all over the map. There isn&#8217;t really a
universally accepted solution, as you can tell by reading the
<a href="https://code.djangoproject.com/wiki/ProfilingDjango">Django wiki</a>. I&#8217;ve
been using
<a href="https://github.com/django-extensions/django-extensions">django-extensions</a>
for a while now, and it has a very nice profiling feature: <code>manage.py runprofileserver</code>. It starts the Django webserver with the (now unmaintained but still useful) <em>hotshot</em> profiler and writes a .prof profiling results file on every request.</p>

<p>So I fired up the profile server and navigated to my view. A .prof file
was added to my /tmp directory. To interpret it, I entered the Django
shell and did the following:</p>

<figure class='code'><figcaption><span>Reading the profiling stats  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">hotshot.stats</span>
</span><span class='line'>
</span><span class='line'><span class="n">stats</span> <span class="o">=</span> <span class="n">hotshot</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">&#39;/path/to/file.prof&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">stats</span><span class="o">.</span><span class="n">sort_stats</span><span class="p">(</span><span class="s">&#39;time&#39;</span><span class="p">,</span> <span class="s">&#39;calls&#39;</span><span class="p">)</span> <span class="c"># sort the output based on time spent</span>
</span><span class='line'><span class="ow">in</span> <span class="n">the</span> <span class="n">function</span>
</span><span class='line'><span class="n">stats</span><span class="o">.</span><span class="n">print_stats</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="c"># print the top 20 culprits</span>
</span></code></pre></td></tr></table></div></figure>


<p>The result of this was as I expected:</p>

<figure class='code'><figcaption><span>Profiling output  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In <span class="o">[</span>6<span class="o">]</span>: stats.print_stats<span class="o">(</span>20<span class="o">)</span>
</span><span class='line'>   557944 <span class="k">function </span>calls <span class="o">(</span>485997 primitive calls<span class="o">)</span> in 3.959 seconds
</span><span class='line'>
</span><span class='line'>   Ordered by: internal <span class="nb">time</span>, call count
</span><span class='line'>   List reduced from 457 to 20 due to restriction &lt;20&gt;
</span><span class='line'>
</span><span class='line'>   ncalls  tottime  percall  cumtime  percall filename:lineno<span class="o">(</span><span class="k">function</span><span class="o">)</span>
</span><span class='line'>     1310    0.763    0.001    0.783    0.001 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/backends/postgresql_psycopg2/base.py:42<span class="o">(</span>execute<span class="o">)</span>
</span><span class='line'>68656/15272    0.485    0.000    1.099    0.000 /usr/lib/python2.7/copy.py:145<span class="o">(</span>deepcopy<span class="o">)</span>
</span><span class='line'>    67792    0.173    0.000    0.173    0.000 /usr/lib/python2.7/copy.py:267<span class="o">(</span>_keep_alive<span class="o">)</span>
</span><span class='line'>     1310    0.152    0.000    0.155    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/backends/postgresql_psycopg2/base.py:116<span class="o">(</span>_cursor<span class="o">)</span>
</span><span class='line'>     3818    0.136    0.000    1.294    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/sql/query.py:223<span class="o">(</span>clone<span class="o">)</span>
</span><span class='line'>10041/5020    0.109    0.000    0.544    0.000 /usr/lib/python2.7/copy.py:234<span class="o">(</span>_deepcopy_tuple<span class="o">)</span>
</span><span class='line'>     2344    0.089    0.000    0.106    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/base.py:275<span class="o">(</span>__init__<span class="o">)</span>
</span><span class='line'>8838/7636    0.076    0.000    0.575    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/utils/tree.py:55<span class="o">(</span>__deepcopy__<span class="o">)</span>
</span><span class='line'>    10258    0.067    0.000    0.072    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/utils/datastructures.py:110<span class="o">(</span>__init__<span class="o">)</span>
</span><span class='line'>     1310    0.057    0.000    0.111    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/sql/compiler.py:218<span class="o">(</span>get_default_columns<span class="o">)</span>
</span><span class='line'>     3654    0.053    0.000    1.816    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/query.py:214<span class="o">(</span>iterator<span class="o">)</span>
</span><span class='line'>     3280    0.050    0.000    2.209    0.001 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/fields/related.py:288<span class="o">(</span>__get__<span class="o">)</span>
</span><span class='line'>21494/19090    0.046    0.000    0.356    0.000 /usr/lib/python2.7/copy.py:226<span class="o">(</span>_deepcopy_list<span class="o">)</span>
</span><span class='line'>     5021    0.045    0.000    0.326    0.000 /usr/lib/python2.7/copy.py:306<span class="o">(</span>_reconstruct<span class="o">)</span>
</span><span class='line'>     1310    0.044    0.000    0.420    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/sql/compiler.py:47<span class="o">(</span>as_sql<span class="o">)</span>
</span><span class='line'>     1310    0.040    0.000    0.069    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/sql/query.py:99<span class="o">(</span>__init__<span class="o">)</span>
</span><span class='line'>     2620    0.037    0.000    0.099    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/sql/compiler.py:749<span class="o">(</span>&lt;lambda&gt;<span class="o">)</span>
</span><span class='line'>     1310    0.037    0.000    0.846    0.001 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/backends/util.py:31<span class="o">(</span>execute<span class="o">)</span>
</span><span class='line'>     3818    0.037    0.000    1.345    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/db/models/query.py:751<span class="o">(</span>_clone<span class="o">)</span>
</span><span class='line'>    10258    0.037    0.000    0.037    0.000 /home/illest/linkrdr/virtualenv/local/lib/python2.7/site-packages/django/utils/datastructures.py:105<span class="o">(</span>__new__<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you can see, psycopg2 is calling <code>execute</code> 1310 times, which is
causing all sorts of slowness. Execute, in case you didn&#8217;t guess, is the
function that executes an SQL query against the database. My view was
making <strong>1310 database queries for a user with 4 feeds</strong>.</p>

<p>Well, now we know what the cause of the slowness is. The question is: how do we fix it? I began by activating the django-debug-toolbar,
which lets you view the number of SQL queries a page generates, among
many other useful things. I confirmed that the number of queries
reported was the same in the debug-toolbar and went about optimizing the
code.</p>

<p>The first approach to optmization in Django should always be to modify the
problematic function without changing anything else. Sometimes, you won&#8217;t be
able to optimize without making changes to your models or other parts
of your application, but this kind of change shouldn&#8217;t be your first
inclination.</p>

<p>So I went back to my view and asked: is there a better way to get the same
data I&#8217;m currently getting? It turns out there is: using <code>select_related</code> in my query.
<a href="https://docs.djangoproject.com/en/1.1/ref/models/querysets/#select-related">select_related</a> populates your QuerySet with the records you requested
plus related records based on ForeignKeys in your model. If I could
change my query to use select related, I could drastically reduce the
number of queries the view required.</p>

<p>There was an issue, though. My models were set up so that a Link
belonged to an Entry, which belonged to a Feed, which had a set of
Users associated. I had gone from the top down: a query filtering feeds
that belonged to the current user. What I needed to do to realize the
benefit of <code>select_related</code> was to get all of the objects I needed in
one query. Since what I really needed was <code>Link</code> objects, I changed the
query to:</p>

<figure class='code'><figcaption><span>Changing the query  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">links</span> <span class="o">=</span> <span class="n">Link</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">select_related</span><span class="p">(</span><span class="s">&#39;entry&#39;</span><span class="p">,</span> <span class="s">&#39;entry__feed&#39;</span><span class="p">,</span> <span class="s">&#39;url&#39;</span><span class="p">,</span> <span class="s">&#39;entry__url&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">entry__feed__users__id</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>This would give me all of the links that I was interested in, plus all
of the related objects that I&#8217;d be using. I reran the view profiling and
saw something unexpected: I was still performing over 600 queries. Using
the debug-toolbar to determine the lines of code generating these
queries quickly revealed my error. When using <code>select_related</code>, you must
make sure to <em>reuse the QuerySet in subsequent code</em>. If you
accidentally use a new QuerySet (even if the objects would have been in
the original QuerySet) it will result in a new database query. This
cascades down to any other objects using the new QuerySet, and now you&#8217;ve
got the same issue again.</p>

<p>After making sure I reused the QuerySet throughout my view and the
functions it called, I reran the view using the debug-toolbar. Finally I
had the results I wanted: all of the data generated in just 2 queries
(the other query was the User&#8217;s Session query, which can&#8217;t really be
avoided). One thing you need to be aware of when using <code>select_related</code>
is that the query can get so large as to be slower than the iterative
approach. That&#8217;s something I&#8217;ll definitely need to keep an eye on in the
future.</p>

<h2>Cleaning Up</h2>

<p>After re-running the tests to confirm my new code worked as expected and
committing the code to git, I had one more task left: update my unit
tests to reflect my new changes. While I didn&#8217;t make any functional
changes, I did make performance changes, and <strong>performance changes
should be unit tested just like functionality changes</strong>.</p>

<p>Helpfully, Django&#8217;s <code>TestCase</code> class has an assertion <code>TestCase.assertNumQueries()</code>
that checks the number of queries performed during a test. I simply
added this assertion the my view test and I was done. This prevents me
from adding code in the future that increases the number of database
queries without forcing myself to decide if that&#8217;s acceptable.</p>

<p>Questions or comments on <em>Profiling Django Applications</em>? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unit Testing in Django]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/11/unit-testing-in-django/"/>
    <updated>2012-02-11T14:17:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/11/unit-testing-in-django</id>
    <content type="html"><![CDATA[<p>As a follow-up to my post <a href="http://www.jeffknupp.com/blog/2012/02/09/starting-a-django-project-the-right-way/">Starting a Django Project the Right Way</a>, I wanted to talk aboue the importance of writing tests for Django applications. I previously mentioned that my first site <a href="http://www.illestrhyme.com">IllestRhyme</a>, has no app specific tests for it. This is both embarassing and true. I&#8217;ve lost countless hours to fixing problems caused by new changes. I wasn&#8217;t going to make the same mistake with <a href="http://www.linkrdr.com">linkrdr</a>. Having a set of unit tests that I can run in an automated fashion has made a world of difference.</p>

<p>The Django <code>unittest</code> framework (really the Python <code>unittest</code> framework) is both simple and powerfull. Along with the test client (<code>django.test.client.Client</code>), there&#8217;s a lot you can
do with Django right out of the box.</p>

<h2>Setup</h2>

<p>To start, we&#8217;ll want to create a dump of our database data to use during testing.</p>

<figure class='code'><figcaption><span>Dump our data</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>./manage.py dumpdata --format<span class="o">=</span>json &gt; my/app/directory/initial_data.json
</span></code></pre></td></tr></table></div></figure>


<p>This will give us a json <a href="https://code.djangoproject.com/wiki/Fixtures">fixture</a> that mimics the current state of our production database. Note that since this is a fixture for <em>all</em> of the apps installed, we&#8217;ve put it in a non-standard directory. To let the test runner find our fixture, we&#8217;ll need to set <code>FIXTURE_DIRS</code> to the directory we just dumped our data to.</p>

<p>Now that we have our data copied, let&#8217;s run whatever tests our installed
apps have already:</p>

<figure class='code'><figcaption><span>Run our tests</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span> python manage.py <span class="nb">test</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>This hopefully gives us output like:</p>

<figure class='code'><figcaption><span>Test run output</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>.....................................................................................................................................................................................................................................................................................................................................................................
</span><span class='line'>----------------------------------------------------------------------
</span><span class='line'>Ran 357 tests in 30.025s
</span><span class='line'>
</span><span class='line'>OK
</span></code></pre></td></tr></table></div></figure>


<p>This is also a good check of the integrity of your database, as Django
will try to load a fixture representing all of your data. If you&#8217;ve been
screwing around with the admin interface or the shell adding
and deleting records, you may have integrity errors. If you do (like I
did), you&#8217;ll have to fix them manually and re-dump your data.</p>

<!--more-->


<p>Once we&#8217;ve got the tests for other apps working, it&#8217;s time to write our
own. They&#8217;ll generally all follow the same pattern:</p>

<ol>
<li>Create a class deriving from django.test.TestCase</li>
<li>If necessary, add a setUp function to prepare data for the tests</li>
<li>Implement test functions with a name starting with &#8216;test&#8217;</li>
<li>Run the tests</li>
</ol>


<p>You should get in the habit of running the tests after each test you
create. Sometimes, you&#8217;ll write a test expecting it to pass but it will
highlight an issue in your code. If you go off and fix the issue without
running the tests again afterwards, you may have unwittingly made
another test fail with your fix.</p>

<p>We&#8217;ll be using <code>django.test.TestCase</code> as the base class for our tests
instead of Python&#8217;s <code>unittest.TestCase</code> because the Django version adds
(from the documentation):</p>

<ol>
<li>Automatic loading of fixtures</li>
<li>Wrap each test in a transaction</li>
<li>Create a TestClient instance</li>
<li>Django-specific assertions for testing for things like redirection and form errors</li>
</ol>


<p>One quick thing to note: <em>all of your test functions names must begin with
&#8216;test&#8217;</em>. If you&#8217;ve never used Python or Django&#8217;s unittest before, you
will be <strong>extremely</strong> frustrated when you define your test classes and
functions, then run the tests only to have nothing happen. There&#8217;s a
practical reason for this decision (so you can create regular functions in your
TestCase derived class), but it drives new users insane.</p>

<h2>Adding a Test</h2>

<p>Time for an example. <a href="http://www.linkrdr.com">linkrdr</a> needs to be able to look-up a URL and
determine if it&#8217;s actually a feed. Here&#8217;s a simplified version of the
code I wrote to do that:</p>

<figure class='code'><figcaption><span>Simple feed checker  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">link_types</span><span class="o">=</span> <span class="p">[</span><span class="s">&#39;application/atom+xml&#39;</span><span class="p">,</span> <span class="s">&#39;application/rss+xml&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;application/rdf+xml&#39;</span><span class="p">,</span> <span class="s">&#39;application/xml&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">is_feed</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
</span><span class='line'>    <span class="n">link_type</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">info</span><span class="p">()</span><span class="o">.</span><span class="n">gettype</span><span class="p">()</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">link_type</span> <span class="ow">in</span> <span class="n">link_types</span>
</span></code></pre></td></tr></table></div></figure>


<p>Simple, right? Let&#8217;s add a test for it. First we&#8217;ll remove anything
hanging around in tests.py (like the initial contents) and start with a
clean file. We&#8217;re going to create a class that derives from
<code>unittest.TestCase</code>. I&#8217;ll call mine <code>IsFeed</code> so I know from the name
what functionality it&#8217;s testing.</p>

<p>So far we have (with the required imports)</p>

<figure class='code'><figcaption><span>Our tests so far  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">django.utils</span> <span class="kn">import</span> <span class="n">unittest</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">IsFeed</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, we&#8217;d like to actually add some tests to our test case. Let&#8217;s check
to make sure my blog&#8217;s atom feed is recognized as a valid feed:</p>

<figure class='code'><figcaption><span>Adding a test  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">django.utils</span> <span class="kn">import</span> <span class="n">unittest</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">IsFeed</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;Tests the functionality of utility.is_feed</span>
</span><span class='line'><span class="sd">    by getting various well-known good feeds and</span>
</span><span class='line'><span class="sd">    making sure they validate&quot;&quot;&quot;</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">test_is_feed_atom</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;Is the url a valid feed?&quot;&quot;&quot;</span>
</span><span class='line'>        <span class="n">url</span> <span class="o">=</span> <span class="s">&#39;http://www.jeffknupp.com/atom.xml&#39;</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">utility</span><span class="o">.</span><span class="n">is_feed</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>You&#8217;ll notice that I documented the test case, and you may be wondering
why, since I&#8217;m a lone developer. Two reasons. First, documentation is
just as useful for yourself as it is for others. Invariably, you&#8217;ll come
back to code you wrote a while ago and decide you were drunk while you
wrote it. It just makes no sense. Having documentation helps in that
respect.</p>

<p>The second reason is more subtle: to prepare to open-source the project.
My goal is to eventually open-source almost all linkrdr that isn&#8217;t
essential to the site. Anyone can write a function to check if a URL is
an RSS or atom feed. It would be nice to have one, though, that&#8217;s been
through a lot of use and checks for odd corner-cases. To that end, I&#8217;m
attempting to keep all of linkrdr PEP8 and PEP257 compliant. It&#8217;s a bit
more to write, but I&#8217;ll be glad I did once I release it into the wild.</p>

<p>Anyway, back to our tests. We should now be able to run the tests using:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span> python manage.py <span class="nb">test</span> &lt;appname&gt;
</span></code></pre></td></tr></table></div></figure>


<p>and get output similar to when we ran the testcases before.</p>

<h2>Code Coverage</h2>

<p>Tests are all well and good, but if you aren&#8217;t testing a vast majority
of your code, they&#8217;re just a false sense of security. Code coverage
tools are designed to intrument your test runs and determine what parts
of your tested code were actually exercised. With code coverage tools,
saying your code is 100% tested is not matter of opinion but rather a provable fact.</p>

<p>I use coverage.py for my code coverage. You can install it using pip via
<code>pip install coverage</code>. Once it&#8217;s installed, rerun your tests like so:</p>

<figure class='code'><figcaption><span>Running coverage.py with unit tests</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span> coverage run manage.py <span class="nb">test</span>
</span></code></pre></td></tr></table></div></figure>


<p>This will produce an instrumentation file that you can convert to HTML
or LaTex, or view from the command line. Run</p>

<figure class='code'><figcaption><span>Viewing coverage reports</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span> coverage report
</span></code></pre></td></tr></table></div></figure>


<p>to get a snapshot of how much of your code is actually being tested by
your unit tests.</p>

<h2>More to Come</h2>

<p>I plan on continuing describing best practices for professional Django
development, started in <a href="http://www.jeffknupp.com/blog/2012/02/09/starting-a-django-project-the-right-way/">Starting a Django Project the Right Way</a> in future posts. Next time I&#8217;ll discuss the TestClient and integrating tests into your deployment system.</p>

<p>Questions or comments on <em>Unit Testing in Django</em>? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing linkrdr]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/10/introducing-linkrdr/"/>
    <updated>2012-02-10T00:49:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/10/introducing-linkrdr</id>
    <content type="html"><![CDATA[<p>I started work on a new site on Monday:
<a href="http://www.linkrdr.com">linkrdr</a>. It&#8217;s the next
generation feed reader for people who subscribe to tens or hundreds of
feeds. linkrdr aggregates your feeds <strong>but more importantly, your links</strong>. It ranks
links according to a relevance formula. Purely chronological based readers
are just <em>terrible</em> at managing a mountain of links.</p>

<p>The idea for linkrdr came from <a href="http://news.ycombinator.com/item?id=3555923">a Hacker News post</a> describing exactly the
problem linkrdr solves. I realized I had exactly the same problem as the
submitter: too many links, too little time. I don&#8217;t want to miss
out on a quality post on a blog that doesn&#8217;t publish very often. At the
same time, if there&#8217;s a link that&#8217;s showing up in a number of my feeds,
it&#8217;s a good bet that it&#8217;s worth reading.</p>

<!--more-->


<p>linkrdr calculates the relevance of a feed entry using two
metrics: number of feeds appearing in and feed post frequency. If you
subscribe to /r/programming and www.somerandomphysicsblog.com, you don&#8217;t
want new posts to have the same weight. /r/programming is updated
constantly, so the chance that an individual entry in the feed is worth
looking at is smaller than from a blog which updates once a week.</p>

<p>On the other hand, if I subscribe to /r/programming and a number of
other programming feeds, and there&#8217;s a link appearing in a bunch of
them, I probably want to read it. linkrdr balances the two metrics to
come up with a score for each entry in your feeds. It then presents your
entries sorted by score, with what it determines to be the most relevant
at the top.</p>

<p>Another problem with feed aggregators is that it&#8217;s not always clear
where something came from. In linkrdr, all entries list their sources
with a link to the original page. So if a popular story was in four of
your feeds, you would see one entry with &#8220;Citations&#8221; showing all of the
feeds it appeared in.</p>

<p>You can (that is, you will be able to) use linkrdr to find new feeds to
subscribe to as well. For each entry in your feed you&#8217;ll see a &#8220;Show
other feeds this appeared in&#8221; link. This will give you a list of all the
currently tracked feeds that had the link, minus the ones you already
subscribe to.</p>

<p>To find new content <em>not</em> in your feeds, you&#8217;ll see a list of popular
entries as determined by the number of feeds they appear in. If everyone
on the Tubes is linking to something, it might be worth checking out
even if it&#8217;s not in one of your feeds.</p>

<p>linkrdr is by not even close to finished , nor even particularly useable at the
moment, but progress is coming quickly. I&#8217;ll describe more of linkrdr&#8217;s
functionality in future posts. For now, if you want to sign up for it
while it&#8217;s free (I may charge a one-time fee if I think the service is
actually useful), go ahead and do so at <a href="http://www.linkrdr.com">linkrdr.com</a>.
I can&#8217;t guarantee stuff will work but signup at least should.</p>

<p>Questions or comments on <em>Introducing linkrdr</em>? Let me know in the comments below.
Also, follow me on Twitter to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Starting a Django Project the Right Way]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/09/starting-a-django-project-the-right-way/"/>
    <updated>2012-02-09T09:13:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/09/starting-a-django-project-the-right-way</id>
    <content type="html"><![CDATA[<p>One of the things I wish I had known when starting my Django project for
<a href="http://www.illestrhyme.com">IllestRhyme</a> was &#8220;How do I start a <em>real</em>
Django project&#8221;. As in, one that&#8217;s actually going to be used and
developed more, not the toy project from the (admittedly execellent)
Django documentation.</p>

<p>Having just gone through this process again for my new site, I wanted to
share the knowledge I&#8217;ve gained about how to properly start a project in
Django. By the end of this post, you will have</p>

<pre><code>1. A fully functional Django project
2. All resources under source control (with git)
3. An environment independet install of your project (using virtualenv)
4. Automated deployment and testing (using Fabric)
5. Automatic database migrations (using South)
6. A solid start to your new site
</code></pre>

<p>None of these steps, except for perhaps the first, are covered in the
official tutorial. They should be. If you&#8217;re looking to start a new,
production ready Django project, look no further.</p>

<!--more-->


<h2>Prerequisites</h2>

<p>A working knowledge of Python is assumed. Also, some prior experience
with Django would be incredibly helpful, but not strictly necessary.
You&#8217;ll need <a href="http://www.git-scm.com">git</a> for version control. That&#8217;s
it!</p>

<h2>Preparing To Install</h2>

<p>I&#8217;m assuming you have Python installed. If you don&#8217;t head over to
<a href="http://www.python.org">python.org</a> and find the install instructions
for your architecture/os. I&#8217;ll be running on a 64-bit Ubuntu server installation hosted by <a href="http://www.linode.com/?r=ae1808f234f8e219de24842336fada09ef81d52f">Linode</a>, with whom I&#8217;m very happy.</p>

<p>So, what&#8217;s the first step? Install Django, right? Not quite. One common
problem with installing packages directly to your current site-packages
area is that, if you have more than one project or use Python on your
machine for things other than Django, you may run into dependency
issues between your applications and the installed packages. For this
reason, we&#8217;ll be using
<a href="http://pypi.python.org/pypi/virtualenv">virtualenv</a> to manage our
Django installation. This is common, and recommended, practice among
Python and Django users.</p>

<p>After installing virtualenv in whatever way you want, create a new
virtualenv, which we&#8217;ll call &#8216;env&#8217;, using the following:</p>

<pre><code>$ virtualenv env
</code></pre>

<p>or, if virtualenv isn&#8217;t in your $PATH (though it should be):</p>

<pre><code>$ python virtualenv.py --distribute env
</code></pre>

<p>Now that we have a virtualenv environment, we need to <em>activate</em> it.
This sets up various envrionment variables to effectively bypass the
system&#8217;s Python install and uses our <code>env</code> one instead. Activate like
so:</p>

<pre><code>$ source ./env/bin/activate
</code></pre>

<p>You should see <code>(env) $</code> at your prompt, letting you know that you&#8217;re
running under the &#8216;env&#8217; virtualenv install. At any time, just type:</p>

<pre><code>$ deactivate
</code></pre>

<p>to stop using virtualenv.</p>

<h2>Installing Django</h2>

<p>&#8220;Wait, &#8216;Installing Django&#8217;? I already have Django installed!&#8221; Fantastic.
You aren&#8217;t going to use it. Instead, we&#8217;ll use one managed by virtualenv
that can&#8217;t be messed up by other users (or yourself) working elsewhere
on the machine. To install Django under virtual env, just type:</p>

<pre><code>$ pip install django
</code></pre>

<p>This should give you the latest version of Django which will be installed in your
virtualenv area. You can confirm this by doing:</p>

<pre><code>$ which django-admin.py
</code></pre>

<p>Which should report an area under our <code>env</code> directory. If it doesn&#8217;t,
make sure you see <code>(env)</code> at your prompt. If you don&#8217;t, you didn&#8217;t
<code>$ source ./env/bin/activate</code>.</p>

<h2>Setting Up The Project</h2>

<p>Before we actually start the project, make sure you have git installed.
It&#8217;s available via package installation on most systems. If it isn&#8217;t for
yours, follow the directions on <a href="http://www.git-scm.com">git-scm</a> to
install via source (not that difficult).</p>

<p>Let&#8217;s start the project via django-admin:</p>

<pre><code>$ django-admin.py startproject myproject
</code></pre>

<p>This creates the <code>myproject</code> directory. Don&#8217;t go there yet.</p>

<h2>Source Control Using Git</h2>

<p>Even though we haven&#8217;t actually done anything besides starting a
project, we know we&#8217;re going to want everything under source
control. We have two sets of &#8216;things&#8217; we&#8217;re going to be commiting: our
Django project files <em>and our virtualenv install</em>. I can already hear
the comments pouring in, but committing your virtualenv install means
you have a <strong>totally reproducible environment</strong> under source control.
This can be critical if you lose your machine or accidentally wipe the
directory.</p>

<p>Our current directory should show two directories: <code>env</code> and
<code>myproject</code>. Since we&#8217;ll be tracking both of these in git, we&#8217;ll
initialize our repository here using:</p>

<pre><code>$ git init
</code></pre>

<p>This creates a git repository in the current directory. Lets stage all of
our files to git to be committed.</p>

<pre><code>$ git add .
</code></pre>

<p>Now we actually commit them to our new repo:</p>

<pre><code>$ git commit -a -m 'Initial commit of myproject'
</code></pre>

<p>If you plan on using a service like Github or Bitbucket, now would be a
good time to push to them.</p>

<h2>Using South for Database Migrations</h2>

<p>One of the most frustrating things in a vanilla Django install is
managing changes to models and the associated changes to the database.
With the help of <a href="http://south.aeracode.org">South</a>, you can realistically create an entire
application without ever writing database specific code. Changes to your
models are detected and automatically made in the database through a
<em>migration file</em> that South creates. This lets you both migrate the
database forward for your new change and <strong>backwards</strong> to undo a change
or series of changes. It makes your life so much easier, it&#8217;s a wonder
it&#8217;s not included in the Django distribution (there has been some talk
of including a database migration tool in Django, but it hasn&#8217;t happened
yet).</p>

<p>Still under our <code>(env)</code> virtualenv environment, install South like so:</p>

<pre><code>$ pip install south
</code></pre>

<p>We setup South by adding it to our INSTALLED_APS in the <code>settings.py</code>
file for the project. Add that now, as well as your database settings
for the project, then run <code>python manage.py syncdb</code>.
You&#8217;ll be prompted for a superuser name and password (which you can go
ahead and enter). More importantly, South has setup the database with
the tables it needs.</p>

<p>You may have noticed that we just ran <code>syncdb</code> without having adding an app to the project. We do this first so that South is installed from the beginning. All migrations to our own apps will be done using South, including the initial migration.</p>

<p>Since we&#8217;ve just made some pretty big changes, now would be a good time
to commit to git. You should get used to committing frequently, as the
more granular the commit, the more freedom you have in choosing
something to revert to if things go wrong.</p>

<p>To commit, first add any untracked files:</p>

<pre><code>$ git add .
</code></pre>

<p>Git users may notice I&#8217;m not adding specific files but rather everything
under our main directory. That&#8217;s becuase, to this point, <em>there isn&#8217;t
anything we don&#8217;t want to commit</em>. Let&#8217;s commit our changes using:</p>

<pre><code>$ git commit -a -m 'Added South for database migrations'
</code></pre>

<h2>Creating Our App</h2>

<p>Use <code>manage.py</code> to create an app in the normal way (<code>python manage.py
startapp myapp</code>) and add it as an INSTALLED_APP. The first thing we&#8217;ll do, before adding models, is
tell South we want to use it for migrations:</p>

<pre><code>$ python manage.py schemamigration myapp --initial
</code></pre>

<p>This creates a migration file that can be used to apply our changes (if
we had any) and also <em>revert</em> them. We use the migration file to  <em>migrate</em> the database changes (even though there are none)
using :</p>

<pre><code>$ python manage.py migrate myapp
</code></pre>

<p>South is smart enough to know where to look for migration files, as well
as remember what was the last migration we did. You can specify
individual migration files, but it&#8217;s usually not necessary.</p>

<p>When we eventually make changes to our model, we ask South to create a
migration using:</p>

<pre><code>$ python manage.py schemamigration myapp --auto
</code></pre>

<p>This will inspect the models in <code>myapp</code> and automatically add, delete,
or modify the database tables accordingly.</p>

<h2>Our Development Area</h2>

<p>One of the things you should get used to is doing development in a
separate area, not where you&#8217;re serving your files from, for obvious
reasons. Git makes this simple and also helps with deployments.
Create a directory somewhere other than where <code>myproject</code> is installed
for your development area (I just call it <code>dev</code>).</p>

<p>In your development directory, clone the current project using git:</p>

<pre><code>$ git clone /path/to/my/project/
</code></pre>

<p>Git will create an exact copy of the <strong>entire</strong> repository. All changes,
branches, and history will be available here. From here on out, you
should be working from your development directory.</p>

<p>Since branching with git is so easy and cheap, create branches
as you work on new, orthogonal changes to your site. Do so by typing:</p>

<pre><code>$ git checkout -b &lt;branchname&gt;
</code></pre>

<p>Which will both create a new branch named <branchname> and check it out.
Almost all of your development should be done on a branch, so that
master mimics the current production master and can be used for recovery at
any time.</p>

<h2>Using Fabric for Deployment</h2>

<p>So we have the makings of a Django application. How do we deploy it?
Thanks to readers of the blog, I&#8217;m a recent convert to <a href="http://www.fabfile.org">Fabric</a>, a fantastic tool perfectly suited to our deployment needs. Install Fabric to our virtualenv like so:</p>

<pre><code>$ pip install fabric
</code></pre>

<p>Fabric expects a file , <em>fabfile.py</em>, to define all of the actions we
can take. Let&#8217;s create that now. Put the following in your <code>fabfile.py</code>
in the <code>myproject</code> directory:</p>

<figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'>    <span class="kn">from</span> <span class="nn">fabric.api</span> <span class="kn">import</span> <span class="n">local</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">prepare_deployment</span><span class="p">(</span><span class="n">branch_name</span><span class="p">):</span>
</span><span class='line'>        <span class="n">local</span><span class="p">(</span><span class="s">&#39;python manage.py test myapp&#39;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">local</span><span class="p">(</span><span class="s">&#39;git add -p &amp;&amp; git commit&#39;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">local</span><span class="p">(</span><span class="s">&#39;git checkout master &amp;&amp; git merge &#39;</span> <span class="o">+</span> <span class="n">branchname</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>This will run the tests, commit your branch change, and merge them into
master. At this point, a simple &#8220;git pull&#8221; in your production area
becomes your deployment. Lets add a bit more to actually deploy. Add
this to your fabfile.py:</p>

<figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'>    <span class="kn">from</span> <span class="nn">fabric.api</span> <span class="kn">import</span> <span class="n">lcd</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">deploy</span><span class="p">():</span>
</span><span class='line'>        <span class="k">with</span> <span class="n">lcd</span><span class="p">(</span><span class="s">&#39;/path/to/my/prod/area/&#39;</span><span class="p">):</span>
</span><span class='line'>            <span class="n">local</span><span class="p">(</span><span class="s">&#39;git pull /my/path/to/dev/area/&#39;</span><span class="p">)</span>
</span><span class='line'>            <span class="n">local</span><span class="p">(</span><span class="s">&#39;python manage.py migrate myapp&#39;</span><span class="p">)</span>
</span><span class='line'>            <span class="n">local</span><span class="p">(</span><span class="s">&#39;python manage.py test myapp&#39;</span><span class="p">)</span>
</span><span class='line'>            <span class="n">local</span><span class="p">(</span><span class="s">&#39;/my/command/to/restart/webserver&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>This will pull your changes from the development master branch, run any
migrations you&#8217;ve made, run your tests, and restart your webserver.
All in one simple command from the command line. If one of those steps
fails, the script stops and reports what happened. Once you fix the
issue, there is no need to run the steps manually. Simply rerun the
deploy command and all will be well.</p>

<p>So now that we have our <code>fabfile.py</code> created, how do we actually deploy?
Simple. Just run:</p>

<pre><code> $ fab prepare_deployment
 $ fab deploy
</code></pre>

<p>Technically, these could be combined into a single command, but I find
it&#8217;s better to explicitly prepare your deployment and then deploy as it
makes you focus a bit more on what you&#8217;re doign.</p>

<h2>Enjoy Your New Django Application</h2>

<p>That&#8217;s it! You&#8217;re ready to start your actual development. If you do a
lot of Django development, just dump all of the commands above into a
fabfile and make creating a proper Django app a one step process. I have
one which I&#8217;ll upload to my github account later today. If you have any
questions or corrections, or think there&#8217;s a tool/step I missed, feel
free to email me at <a href="mailto:jknupp@gmail.com">jknupp@gmail.com</a> or leave
a comment below. <a href="http://www.twitter.com/jeffknupp">Follow me on Twitter</a> to get all of the latest blog updates!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Your Second Django Site]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/08/building-your-second-django-site/"/>
    <updated>2012-02-08T05:03:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/08/building-your-second-django-site</id>
    <content type="html"><![CDATA[<p>I started work on my second Django powered site today. It&#8217;s not
ready to be unveiled, but I&#8217;ve realized that, while your first site will
always be your baby, your second is where you start to hit your stride.</p>

<p>So what have I done differently? For one, <strong>testing</strong>. For
<a href="http://www.illestrhyme.com">IllestRhyme</a> I never wrote any tests, which
has caused me no end of troubles. Now that the site is stable and
actively used, it&#8217;s difficult to make myself go back and write tests,
though I know I need to. The new site has unit tests for
everything, and though it&#8217;s somewhat of a pain to do, it will most
certainly pay dividends in the long run.</p>

<p>In the production environment, everything is running
under <a href="http://pypi.python.org/pypi/virtualenv">virtualenv</a>, Python&#8217;s unofficial answer to the problem of running multiple
Python environments. It effectively does a clean Python install to a local
directory and hijacks <code>pip</code> and <code>easy_install</code> commands to install
packages locally. This guarantees packages for the new site don&#8217;t clash
with packages for the old site.</p>

<p>Also, I&#8217;m using <a href="http://www.fabfile.org">Fabric</a> for automating deployment tasks. While before I relied on a set of git hooks, this became a bit cumbersome. Fabric is fantastic for deployment. My fabfile backs up the site, downloads packages from git, creates symlinks, run South migrations, runs the tests, and reloads Apache. Deployment should really be a one-button-press activity. Fabric makes it easy. Thanks to a number of commenters (Alexis Bellido on this site, joelhaasnoot, spleeyah, jsvaughan, and marcofucci on Hacker News)  for pointing this out on a previous post.</p>

<!--more-->


<p>Still using Git as my DVCS, but now I&#8217;ve got 100s of commits to
a number of projects under my belt. This time around, git is a tool and
not a chore (the chore being actually learning it properly).</p>

<p>On the internals side, a lot of what I&#8217;m doing on the second site is in
pure Python (and some may eventually be in C++ libraries). Due to the nature of the site, storing everything in the
database would quickly lead to space issues, so much is generated
dynamically. For long-running tasks, I&#8217;m using
<a href="http://www.celeryproject.org">Celery</a> and <a href="https://github.com/ask/django-celery">django-celery</a>. They&#8217;re a breeze to work with. Tasks in Celery are basically fire and forget and the interface stays out of your way.</p>

<p>If you were to look at my first site, you could almost tell the date a
file was written by reading the code. I was learning Django by doing,
and a lot of the early stuff is pretty rough. I&#8217;ve rewritten a lot of
it, but it&#8217;s there. With the new site, I&#8217;m writing idiomatic Django (if there is such a thing)
from the start. Simple decisions like naming all of your views and
referring to them using <code>url my_view_name</code> were
made in the beginning, not halfway through the project when I first learned about them. After getting one large-scale Django site under your
belt, you should notice that the framework doesn&#8217;t get in your way as
much. The boilerplate forms, views, and models come easy, leaving you
time and energy to work on the interesting stuff.</p>

<p>And it&#8217;s the interesting stuff that should be the focus of your second
(personal) Django site. While a simple CRUD based application is a noble
goal for your first site, your second should push boundaries. My new
site has a whole host of interesting computational and optimization
problems, and those are fun to work on. Figuring out how to exclude a
field on a ModelForm for the first time is not.</p>

<p>One last thing. A number of people have asked me recently how difficult
it was to learn Django from scratch and take a site live, either out of
curiosity or because they&#8217;ve wanted to do the same thing. My answer:
the coding is easy; building something people want to use and getting
them to use it is hard. <em>Really hard</em>. It requires a totally different skill-set from
programming, but it&#8217;s incredibly rewarding to even attempt. To anyone who&#8217;s been toying
with the idea of launching a web site, as I had for years, I urge you to do so. The skills you
pick up in launching a site are invaluable and will positively impact
your career.</p>

<p>Questions or comments on <em>Building Your Second Django Site</em>? Let me know in the
comments below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts
and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Analytics for Django Sites]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/07/analytics-for-django-sites/"/>
    <updated>2012-02-07T22:44:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/07/analytics-for-django-sites</id>
    <content type="html"><![CDATA[<p>This is the first in a series of posts I plan to do over the next month about Analytics and Django. In this post I&#8217;ll walk through how I began to use a number of analytics tools to
drive decisions about my site, <a href="http://www.illestrhyme.com">IllestRhyme</a>.</p>

<p>One of the first things I did when writing
<a href="http://www.illestrhyme.com">IllestRhyme</a> was to sign up for Google
Analytics. I had never run a web site before, but I was aware of
Google&#8217;s analytics offering. I admit, for the first few weeks after the
site went live I would start at the Google Analytics page and <strong>hope</strong> to
see users in the Live View. I wasn&#8217;t really using the data for anything.
I was using Google Analytics as a virtual scoreboard.</p>

<p>It wasn&#8217;t until I signed up for <a href="http://getclicky.com/66528953">Clicky</a>
that I started to take analytics seriously. In fact, more specifically,
it was when I combined Clicky and
<a href="https://github.com/jcassee/django-analytical">django-analytical</a> that I
really took my first deep-dive into using analytical data for decision
making. Since django-analytical already integrates with a number of
analytics services, including Clicky, setup was a breeze. Sure, I could
have inserted the raw code into my Django templates, but
django-analytical gave me a single point at which to configure all my
analytics services.</p>

<p>More importantly, and I can not stress this enough,
<strong>django-analytical&#8217;s Clicky integration let me see my users in Clicky via
their contrib.auth usernames</strong>. This was <strong>huge</strong>. Now, instead of
staring at IP addresses, I could follow users on their visit to the site (using
<a href="http://getclicky.com/66528953">Clicky&#8217;s</a> awesome Spy feature) in
real-time by username. Believe me, nothing will teach you more about you
users than recognizing usernames and their associated behavior patterns.
I could tell which users were hitting the site to check quickly for
updates, which users hung around for a while, and which users <em>used the
site like it was crack</em>. It was this last group that I was initially
interested in.</p>

<!--more-->


<p>I discovered I had about four or five <em>hardcore</em> users, that were on the
site for hours a day. Now, part of that is just personality, but in
addition, <em>something on the site clicked for them</em>. Since I want all my
users on the site for hours a day, I decided to determine what they were
doing in a more rigorous fashion. Naturally, I started coding&#8230;</p>

<p>I ended up writing a middleware that tracked a configurable set of users as
they browsed the site and stored this information in the database. I
then processed this information and organized it into &#8220;activities&#8221;. If a
user was going through all the new rhymes submitted and voting on them,
this was &#8216;updating&#8217;. If the user was submitting a bunch of new rhymes,
this was &#8216;bulk submitting&#8217;, etc. After analyzing this information for my
power users and a random sampling of other users, I noticed they were doing one thing more than any other,
which I didn&#8217;t even have a category for: they were following each other.</p>

<p>This was strange to me, as I didn&#8217;t think of IllestRhyme as a community.
To me it was more like a tool to get better at rapping. To some of my users, at least, it
was a destination; a way to interact with like-minded people. I quickly
realized the value of this and set to work adding tools that would
encourage this interaction.</p>

<p>Using
<a href="https://bitbucket.org/psam/django-postman/wiki/Home">django-postman</a> I
gave them the ability to send Private Messages. I encouraged commenting
by increasing the amount of Rep (virtual points representing a user&#8217;s
&#8216;reputation&#8217; on the site, sort of like StackOverflow) adding comments
was worth. Voting on other users&#8217; verses also received a boost.</p>

<p>That&#8217;s just one example of the ways I use the analytics data I collect
from <a href="http://getclicky.com/66528953">Clicky</a>, Google Analytics, HubSpot,
and the rest to make decisions about my site. In my next Analytics post,
I&#8217;ll take a look at A/B testing in Django. Stay tuned!</p>

<p>Questions or comments on <em>Analytics for Django Sites</em>? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Coding Backwards]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/07/coding-backwards/"/>
    <updated>2012-02-07T09:55:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/07/coding-backwards</id>
    <content type="html"><![CDATA[<p>At my real job I&#8217;ve been working in my spare time on a large-scale Python testing framework. When I decided our current framework didn&#8217;t meet our needs, I took a new approach (for me) to developing software: <em>coding backwards</em>. Since doing so, I&#8217;ve learned that coding backwards can, <em>but not will</em>, lead to the creation of some fabulous APIs.</p>

<p>The idea for coding backwards was most clearly verbalized for me by
Aaron Swartz and his <a href="http://webpy.org">web.py</a> framework. He says:</p>

<blockquote><p>I wrote a web application in Python just imagining how I wanted the API<br/> to be. It started with import web, of course, and then had a place to<br/> define URLs, simple functions for GET and POST, a thing to deal with<br/> input variables and so on. Once the code looked right to me, I did<br/> whatever it took to make it execute without changing the application<br/> code &#8211; the result was web.py.</p></blockquote>


<p>This was a revelation for me. When you&#8217;re building software for others
to use, <strong>make it as natural as possible for them to do so</strong>. I call
this <em>coding backwards</em>. It directly influenced how I built my testing
framework.</p>

<p>I started with the finished product: a test script written in Python. I
wrote valid Python code against a library that didn&#8217;t exist yet. Without
an existing API to get in my way, I was able to express my intentions
clearly. Anyone reading the test script would immediately know what was
happening. More importantly, they wouldn&#8217;t be exposed to weird
implementation quirks. It was my version of the &#8220;optimal&#8221; test script for our system in Python.
After writing that script, there was only one problem: it didn&#8217;t
actually do anything yet.</p>

<p>From the test script, I created the classes and functions that the test
script called. What I did within the library was less important than
<em>not changing the test script to fit the library</em>. If I have to make a
few weird implementation decisions as a result, fine. The point is,
<strong>users are going to use the library&#8217;s API, not the library&#8217;s
internals</strong>. Of course, that doesn&#8217;t mean the implementation can be
spaghetti coded crap. It must be implemented professionally, just with
making the test script work as expected the primary goal.</p>

<p>Coding backwards prevents you from writing functionality that no one
will use, because someone is already using all of your library. That
keeps the interfaces tight and well defined. With something like a
testing framework, the interface is king. The ratio of test case writers
to test framework maintainers will be something like 10:1, so creating a
friendly, usable interface is key.</p>

<p>In actually writing the implementation, I found myself bouncing around
between the top level interface code and the lowest level library code
quite a bit. I would create a top level class or function, realize it
would need to call some library code, then go off and write that library
code. Again, though, I was coding backwards. I didn&#8217;t start off writing
a bunch of low level libraries I thought I would need. I deferred
creation of the libraries until I actually needed them.</p>

<p>This lends itself well to writing tests. At each point, you&#8217;re writing
the minimum required to get the interface working. Sounds suspiciously
like the methodology for creating unit tests. In practice, writing tests
naturally fit into the development flow. This is most decidedly <em>a good
thing</em>.</p>

<p>While the framework isn&#8217;t complete, it certainly is usable. What&#8217;s more,
it usable by just about anyone without having to even look at the
interface. Since I created the test script first, I have a wonderful
example to show the library&#8217;s canonical use. I&#8217;ve been quite happy with
the results of coding the framework backwards. It puts emphasis on the
interface rather than the implementation, which is exactly where the
emphasis should be in a testing framework.</p>

<p>Questions or comments on <em>Coding Backwards</em>? Let me know in the comments
below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts and
updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Git with Django]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/07/using-git-with-django/"/>
    <updated>2012-02-07T07:57:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/07/using-git-with-django</id>
    <content type="html"><![CDATA[<p>When I started <a href="http://www.illestrhyme.com">IllestRhyme</a>, I had never used git . Git gives me distributed version
control and the ease (and speed!) of the git workflow for a slight learning
curve. Below is how I set up my Django project to use git, from start to
finish.</p>

<p>To begin, I had my Django project already created and a bit of code in
there, so I needed to &#8220;add&#8221; it to a new git repo. All that&#8217;s needed for
this is to <code>cd</code> into the top level directory and run <code>git init .</code> This
sets up a git repo in the directory, <strong>but doesn&#8217;t commit the files.</strong>
Before committing, we&#8217;ll want to setup our <code>.gitignore</code> file to tell
git what files not to track in version control. Since I&#8217;m working with Python files using
vim, my <code>.gitignore</code> file has the following contents:</p>

<pre><code>*.pyc
*.swp
local_settings.py
</code></pre>

<p>The <code>local_settings.py</code> file is part of my development workflow, as
explained in <a href="http://www.jeffknupp.com/blog/2012/02/05/django-production-deployment-using-git/">this post</a>. After we create
the <code>.gitignore</code> file, we add <em>everything</em> to the repository, using <code>git
add .</code> This stages all of our files for commit to git. At this point, we
can run <code>git commit</code> to actually commit our files for the first time.</p>

<p>At this point, we have our Django project in a (local) git repository. I
use Bitbucket as a &#8220;backup&#8221; git repo in case I lose my web server. As
you might have guessed, I do all my work on the web server directly
using ssh, gvim, and X tunneling. This is not necessarily recommended
for large projects, but it works well for a single developer. Whenever I
make a change and commit it, I use <code>git push</code> to push the commit to
Bitbucket, so that Bitbucket always has the latest copy of the repo.</p>

<p>Once we&#8217;ve committed to git, the first thing to do is clone our
repository to create a development environment in a new area on our
machine reserved for development. If you&#8217;re cloning on the
same machine, you&#8217;ll use <code>git clone &lt;path/to/original/git/repo&gt;</code>. Github
or Bitbucket users will use <code>git clone &lt;remote repository&gt;</code>, where
&#8221;<remote repository>&#8221; is what the service shows is the URL for your repo. Regardless,
clone your repo to create a dev environment that exactly mirrors your
prod environment.</p>

<p>In our new development area, we&#8217;ll first want to create a
branch, using <code>git branch &lt;branchname&gt;</code>. Git creates a branch of the
current branch (which for us will have been &#8216;master&#8217;). <strong>It does not,
however, switch you to that branch.</strong> To switch to working on your new
branch, use <code>git checkout &lt;branchname&gt;</code>. To see what branches are
available, just type <code>git branch</code>. The branch you are currently on will
be marked with a &#8216;*&#8217;.</p>

<p>Once you&#8217;ve done some work on your branch that you&#8217;re happy with, it&#8217;s
time to commit. If you added files during this phase, run <code>git add
&lt;filenames&gt;</code> to stage them to be committed. Alternately, you can use
<code>git add .</code> to add <em>all</em> untracked files to be committed. From here,
just commit using <code>git commit &lt;changedfiles&gt;</code> or <code>git commit -a</code> for all
changed files that git is tracking.</p>

<p>Now it&#8217;s time to merge your changes back into your master branch. Switch
back to the master branch with <code>git checkout master</code> and merge the
changes with <code>git merge &lt;branchname&gt;</code>. If there are no conflicts, <em>git
will autocommit the merge changes</em> and nothing more needs to be done. If
conflicts do arise, manually fix them and <code>git commit</code> them. Git will
prepopulate the commit message with something like &#8216;Merge from
<branchname>&#8217;, which you can replace or, better yet, enhance.</p>

<p>Now that we&#8217;ve got our changes committed to the master branch in our
development area, it&#8217;s time to push them to production. If you&#8217;re using
a service like Github or Bitbucket, first push the changes there with a
<code>git push</code>. Next, <code>cd</code> into your production area and pull down the
changes using <code>git pull</code> (or <code>git pull &lt;development repo area&gt;</code> for a
repo on the local machine). This should update the master branch in your
production area with all of the changes committed from development.
That&#8217;s it! You&#8217;ve successfully used git to manage changes in a Django
project!</p>

<p>I&#8217;m certainly no git guru and there are likely aspects of this workflow
that can be enhanced or simplified. If you see something that doesn&#8217;t
make sense or can be streamlined, please let me know in the comments.
I&#8217;m always looking to improve my git-Fu!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Responding Quickly To Customers]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/06/on-responding-quickly-to-customers/"/>
    <updated>2012-02-06T03:18:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/06/on-responding-quickly-to-customers</id>
    <content type="html"><![CDATA[<p>When I wrote my last post, which hit the frontpage of HackerNews, I
wanted to see what the HNers would see. So I cleared my cookies, logged
out, and navigated over to <a href="http://www.illestrhyme.com">IllestRhyme</a>.
When I got there, something caught my eye:</p>

<p><img src="http://www.illestrhyme.com:8080/images/chat.jpg"></p>

<p>It&#8217;s normal for me to be talking to users, and normal for me to be
responding to requests from users. <strong>If this isn&#8217;t normal for you, it should be</strong>.
Part of the reason IllestRhyme has a community feel is that the users
get the sense that their requests don&#8217;t go off into the ether. I&#8217;m
hanging around, reading their emails, forum posts, and chat transcripts.
If they suggest something, I almost always implement it. What&#8217;s more,
they are rewarded for their suggestion through Rep points, which tracks
reputation on the site.</p>

<p>I love the size of the site as it is right now. Sure, I want the number
of users to explode, but with about 150 users, I know all of them, talk
to them frequently, and have a general idea of the type of user they are
(power, casual, etc).</p>

<p><strong>The number of users on the site may go up, but my interaction with them
won&#8217;t end.</strong> My first hire would ideally be a community rep. I can take
care of the programming and marketing, but I never want my users to feel
like they don&#8217;t have my ear.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Django Production Deployment and Development Using Git]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/05/django-production-deployment-using-git/"/>
    <updated>2012-02-05T21:11:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/05/django-production-deployment-using-git</id>
    <content type="html"><![CDATA[<p>When I started <a href="http://www.illestrhyme.com">IllestRhyme</a>, I had never before managed a web application. Much was similar to enterprise development. Much wasn&#8217;t. One of the things I had no idea about was how to manage production deployment of a web app. I settled on some common Django trickery and Git, and it has worked like a charm.</p>

<p>I knew going in that I would use Git for source control. I wanted a distributed version control system to give me an opportunity to work anywhere git was installed. I didn&#8217;t suspect I would use git for deployment, also.</p>

<p>When the site began, I didn&#8217;t even have a &#8220;deployment&#8221; strategy. There were so few visitors to the site that I could work on it live. Within two weeks, it was clear I couldn&#8217;t be showing users HTML 500 errors as frequently as I had been. I needed to start acting like I was working on a &#8220;real&#8221; project.</p>

<p>(Re)Enter Git. <!-- more -->I would have a few mis-starts before I settled on a safe, productive way to work. Initially, I created a new directory on my machine for development. I cloned my git repository and created a dev branch. The dev branch had the same settings.py file as the master branch, and I was editing this manually as I switched between the dev and master branches. I knew this was a dangerous practice, and this proved true when I hosed the production database because of a bad settings file. Good thing I had DB backups&#8230;</p>

<p>There had to be a better way. I decided that, since the Django settings.py file was just Python, I would create a <code>localsettings.py</code> file that the settings.py file would import. For development, this would point to the development database and settings. For production, the production settings. This file is imported by the settings.py file and is not tracked by git (there&#8217;s an entry for it in the .gitignore file).</p>

<p>Now I was free to work on my dev branch without worrying about messing up production. When I was happy with a change, it was merged with the master branch and pushed to bitbucket. Then the production area pulled down the changes and Apache was restarted. Perfect.</p>

<p>Something that took a bit to get used to using git was branching. In enterprise development with CVS or SVN, branches are more substantial &#8220;things&#8221; then personal development with git. A branch in git can both be created and deleted quickly. I frequently have five or six active branches of development for <a href="http://www.illestrhyme.com">IllestRhyme</a>: some for large sweeping changes that require database migrations, some just adding a few new pages/views to the site, some as small as correcting typos or adding a link or two.</p>

<p>Where git really shines is in switching between active branches. I can be working on a branch with 70 new files, say <code>git checkout &lt;somesmallbranch&gt;</code>, and everything is exactly as it should be, with the added files removed and the changes merged back to my small change branch. This allows me to work almost in real-time. If I&#8217;m deep in a change but get alerted to an error via email, I can quickly switch to my main dev branch, make a change, test it, commit it and pull it down in mere minutes.</p>

<p>Git has opened up a new world for me in terms of productivity. It&#8217;s been so useful on IllestRhyme that I&#8217;ve begun to use it at my day job as an &#8220;out-of-band&#8221; VCS. I checkout with our enterprise VCS, do a quick <code>git add .</code> to my personal git repository, and branch/commit/merge to my heart&#8217;s content. When I&#8217;m happy with my changes, I commit to my enterprise VCS, which has been instructed to ignore my .git directory.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advertising: Reddit versus Facebook]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/02/advertising-reddit-versus-facebook/"/>
    <updated>2012-02-02T05:07:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/02/advertising-reddit-versus-facebook</id>
    <content type="html"><![CDATA[<p>To acquire users for <a href="http://www.illestrhyme.com">IllestRhyme</a>, a user content driven rap site I started, I ran two ads: one on Reddit and one on Facebook. The results were startling.</p>

<p>According to the data from <a href="http://getclicky.com/66528953">Clicky</a>, the analytics engine I use most, Reddit sent me roughly 170 visitors for a 3 day ad, purchased at $30 per day. Of those visitors, only 5 registered for the site. That gives me a conversion rate of 2.8%, at a cost of $18. I&#8217;m happy to eat the cost up front for new users as they&#8217;re the lifeblood of the site, but $18 is pretty extreme.</p>

<p>After the Reddit ad ran its course, I created a Facebook ad with the same parameters: $30 a day, however many visitors that buys me. In the first 12 hours of the Facebook ad, I received 33 visitors, <em>9 of whom signed up</em>. Now I realize it&#8217;s still a bit early to call the race, but even if I get no more visitors from the Facebook ad, my cost of acquisition was $10, 55% cheaper than for the Reddit ad. If my <em>27% conversion rate</em> keeps up, 170 visitors would net me 46 users, at a cost of only $1.96.</p>

<p>I realize this data isn&#8217;t comprehensive, but it&#8217;s still eye opening. Part of this can be attributed to the more focused targeting I was able to do through Facebook. Facebook let me specify that my ad only be shown to the 7 million or so users who:
1. Live in the US
2. Are 18 or older
3. like #Freestyle rap, #Hip hop music, or #Rapping</p>

<p>Conversely, on Reddit I was forced to choose a subreddit to advertise on (along with a small percentage of the site at large). I chose /r/hiphopheads as it&#8217;s a large (by Reddit standards) and active subreddit.</p>

<p>Regardless of the targeting differences, I think it&#8217;s safe to assume that Facebook users are at least more willing to sign up for websites than are Reddit users. Interestingly, I use the Facebook registration app for my registration form. It&#8217;s not clear from the data (I&#8217;m running an A/B test now), but it appears that Facebook users are more willing to sign up if they are presented with a Facebook form to fill out. For Reddit users, who are more Internet savvy, this may actually be a deterrent.</p>

<p>Of course this doesn&#8217;t take into account what <em>kind</em> of users those who registered will turn out to be. It may be the case that Facebook users are more likely to sign up for something and never use it (although the initial data indicates this isn&#8217;t the case, at least categorically). Those five Reddit users may be the five most active users on IllestRhyme for the next year. For $18 a piece, they better be.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How Django Makes Web Programming Stupidly Easy]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/02/how-django-makes-web-programming-stupidly-easy/"/>
    <updated>2012-02-02T03:59:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/02/how-django-makes-web-programming-stupidly-easy</id>
    <content type="html"><![CDATA[<p>I developed <a href="http://www.illestrhyme.com">IllestRhyme</a> using Django, having never touched it before. I chose it because it&#8217;s Python based, and a quick search showed there were a lot of third-party applications available. In two weeks, I had a fully functional site. The site has come a long way since it launched in the beginning of January (looking at the git commit comments is especially fun), but what let me add features so quickly was the third party apps.</p>

<p>First off, some best practices. When I began intalling applications I did so using pip, which downloads packages (by default) from <a href="http://pypi.python.org">PyPi</a>, the Python Package Index. This seemed reasonable, as I wanted stable versions of packages and an easy way to reinstall everything in case of emergency. The packages on PyPi, howevery, usually trail the main branch of a project, sometimes significantly so. So I went back and removed all of the pip-installed packages and checked everything out from source.</p>

<p>I can still rebuild everything in an emergency since (a) my entire site is under source control and (b) setting up a Python dependecies file to download the packages I require was a breeze. Ok, enough meta-discussion. The real question is, &#8220;what applications am I using?&#8221; Here&#8217;s the current list:</p>

<ul>
<li>django.contrib.auth</li>
<li>django.contrib.contenttypes</li>
<li>django.contrib.sessions</li>
<li>django.contrib.sites</li>
<li>django.contrib.messages</li>
<li>django.contrib.staticfiles</li>
<li>django.contrib.sitemaps</li>
<li>south</li>
<li>django.contrib.admin</li>
<li>django.contrib.admindocs</li>
<li>voting</li>
<li>django.contrib.comments</li>
<li>basic.inlines</li>
<li>basic.blog</li>
<li>basic.groups</li>
<li>tagging</li>
<li>django.contrib.markup</li>
<li>pybb</li>
<li>pytils</li>
<li>sorl.thumbnail</li>
<li>pagination</li>
<li>postman</li>
<li>oembed</li>
<li>analytical</li>
<li>basic.tools</li>
</ul>


<p>Those applications gave me, in no particular order: forums, a blog, voting on user defined objects, database migrations, tagging, analytics integration, groups (&#8220;Crews&#8221; on the site) and group membership workflows, and oEmbeded links. Most required minimal setup. More importantly, they allowed me to quickly deliver features that users wanted while being able to focus on the site&#8217;s core features, which were written from scratch.</p>

<p>In addition to being well written, most are very well documented, either via an .rst file on github/bitbucket or, even better, a Sphinx generated page on <a href="http://www.readthedocs.org">ReadTheDocs</a>. And the best part about them is they&#8217;re all open source, so they&#8217;re eminnently moldable if you&#8217;re doing something a little outside the lines. Since you have the source, it&#8217;s trivial to fork the code and change it locally, merging bug fixes from the main branch. This is another reason why using the checked out code is superior to PyPi packages: you get bugfixes and features as soon as they&#8217;re written.</p>

<p>For all of Django&#8217;s plusses, though, there are some minuses. The framework can be rigid at times, forcing you into a particular way of doing things. Often that&#8217;s not an issue, but sometimes you want the framework to just &#8220;get out of your way&#8221; and code closer to the bare metal. Those who are interested in a bit less restrictive frameworks should check out web.py and Pylons. That said, working within the framework (the way it&#8217;s meant to be used) can lead to a huge productivity increase, as so much is taken care of for you. In the end, it&#8217;s just Python code, so you almost always have an &#8220;out&#8221;.</p>

<p>What&#8217;s interesting with Django is how my development process has matured since starting the site, something I&#8217;ll go into in a future post. For now, if you have any Django related questions, feel free to hit me up at <a href="mailto:jknupp@gmail.com">jeff@jeffknupp.com</a>&#8230; Or do what everyone else does and Google until you find a StackOverlow question that matches yours.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting Up Octopress/Jekyll with Apache]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/02/setting-up-octopress-slash-jeckyll-with-apache/"/>
    <updated>2012-02-02T02:06:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/02/setting-up-octopress-slash-jeckyll-with-apache</id>
    <content type="html"><![CDATA[<p>So now that I got my &#8220;Hello World&#8221; post out of the way, I think it would be instructive to describe the setup process for this blog. Octopress is exactly what I&#8217;ve been looking for: a well styled, static page based blogging engine that doesn&#8217;t get in my way. The fact that Jekyll (on which Octopress is based) is so closely integrated with git is a definite plus. So how did the install go? First some background.</p>

<p>I&#8217;m the founder of <a href="http://www.illestrhyme.com">IllestRhyme.com</a>, a site where users post rap verses they wrote and other users comment/vote on them. There&#8217;s a ton of other features, but that&#8217;s the gist of it. Anyway, I run IllestRhyme on a <a href="http://www.linode.com/?r=ae1808f234f8e219de24842336fada09ef81d52f">Linode</a> server running Ubuntu. I use Apache for dynamic content and Lighttpd for static content. Since I already have a Linux machine on the Interwebs, I followed the <a href="http://octopress.org/docs/setup/">instructions</a> on my Linode machine&#8230; which is to say I basically copy and pasted the instructions:</p>

<pre><code>rvm install 1.9.2 &amp;&amp; rvm use 1.9.2
git clone git://github.com/imathis/octopress.git octopress
cd octopress    # If you use RVM, You'll be asked if you trust the .rvmrc file (say yes).
gem install bundler`
bundle install`
</code></pre>

<p>Everything went smoothly. Next I needed to make Apache serve both www.jeffknupp.com and www.illestrhyme.com. I created a new file in /etc/apache2/sites-available/ named &#8216;jeffknupp.com&#8217; and added the normal VirtualHost settings. After running <code>sudo a2ensite jeffknupp.com</code> and reloading apache (<code>sudo service apache2 reload</code>), Apache helpfully warned me that I didn&#8217;t have NameVirtualHost set and nothing was going to be listening on port 80. After quickly adding <code>NameVirtualHost 50.116.49.236:80</code> to my apache2.conf file, I reloaded again. I pointed my browser to www.jeffknupp.com and&#8230; saw a directory listing of my Octopress install. One quick edit to my jeffknupp.com site configuration and I was good to go. I successfully saw my Hello World post.</p>

<p>So how long did this all take? Maybe 20 minutes, and most of that was installing Ruby. I&#8217;m quite happy with the result: I now have a blogging engine &#8220;for hackers&#8221; that suits my needs perfectly.</p>
]]></content>
  </entry>
  
</feed>
