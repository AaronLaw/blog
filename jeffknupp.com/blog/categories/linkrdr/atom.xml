<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linkrdr | Hackers Gonna Hack]]></title>
  <link href="http://www.jeffknupp.com/blog/categories/linkrdr/atom.xml" rel="self"/>
  <link href="http://www.jeffknupp.com/"/>
  <updated>2012-07-10T06:02:38-04:00</updated>
  <id>http://www.jeffknupp.com/</id>
  <author>
    <name><![CDATA[Jeff Knupp]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Django Memcached: Optimizing Django Through Caching]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/24/django-memcached-optimizing-django-through-caching/"/>
    <updated>2012-02-24T09:00:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/24/django-memcached-optimizing-django-through-caching</id>
    <content type="html"><![CDATA[<p>Caching is a subject near and dear to the heart of many
peformance-minded programmers. For those coming to web programming
without other programming experience, caching may be a new topic. For
programmers new to the web, using an external cache may be an approach
not yet considered. In this post, I'll describe how, through the use of Django's caching support, I was able to <strong>reduce <a href="http://www.linkrdr.com">linkrdr's</a> page load time from over 3.5 seconds to 0.01 seconds.</strong></p>

<!--more-->


<h2>What is Caching?</h2>

<p>Caching is a word that changes meaning a bit depending on the context in which it's used, but in the general sense, <em>caching is the process by which the result of previous computation is saved and reused without re-performing the computation.</em> In the Django specific sense, there are three different types of caching:</p>

<ol>
<li><p><strong>The per-site cache</strong>: Saves the result of requests to all URLs
for reuse when a request for the same URL is later made.</p></li>
<li><p><strong>The per-view cache</strong>: Saves the result of requests resolving to
specified views for reuse when a request resolving to the same
view is made.</p></li>
<li><p><strong>The low-level cache API</strong>: Used by the developer to set, retrieve, and maintain objects in the cache manually.</p></li>
</ol>


<p>While the first two methods are certainly useful for some sites, the third is the most interesting. Caching requires some backend cache (obviously), and Django ships with a few out of the box. It can keep the cache in memory (not particularly useful when new threads are spawned for HTTP requests by the HTTP server), in the database (fine but slow), or on the filesystem (ditto).</p>

<p>Then there's <a href="http://memcached.org">Memcached</a>. Memcached is pretty well known in the web development community as an extremely flexible, scalable, and resilient external caching solution. The fact that Django ships with a "low-level" API for interacting with Memcached is great, although it does require the installation of a Python/Memcached interface package, of which there are two: python-memcached and pylibmc. Let's investigate using Memcached via a case study.</p>

<h2>Case Study: linkrdr.com Page Load Time Optimization</h2>

<p>I've talked about <a href="http://www.linkrdr.com">linkrdr's</a> optimization
techniques before. The main view shows links from entries in a
user's subscribed feeds. These links have been aggregated and sorted according to a ranking algorithm. For example, if a user subscribes to 10 RSS feeds and follows a few Twitter users and 4 of those sources mention a particular link, that link should appear higher in your list of links to read than a link from a single feed entry.</p>

<p>Retrieving, analyzing, aggregating, and sorting all of the links from all of the entries from all of a user's subscribed feeds is computationally expensive. The calculation of a link's "importance" was optimized by <a href="http://www.jeffknupp.com/blog/2012/02/15/optimizing-django-views-with-c-plus-plus/">rewriting the calculation in C++ and calling it from the view</a>. The database query <a href="http://www.jeffknupp.com/blog/2012/02/14/profiling-django-applications/">was similarly optimized</a>. These proved not to be enough, however, in the face of a flood of new users (and new data) to linkrdr.</p>

<p>3.5 seconds. That was how long it took to generate the data within the
main view function. Previously, it had been under a second, but after a
sudden flood of users and data, things had gotten out of control. I knew that I needed to implement caching to cut down page load time, but there were a few wrinkles. First, the datasets linkrdr returns are rather large, even with pagingation reducing the items shown to 100 per page. Second, a link had two real scores: one that could be calculated just by inspecting the link's properties in isolation and one that could only be calculated with respect to <strong>all</strong> the other links in a user's feed. These issues combined led to an interesting optimization problem.</p>

<p>The first goal was to cache all the user's sorted links whenver a
request came in, to be used in subsequent requests. I originally tried
to cache the entire result set like so:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Caching the results  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="n">request</span><span class="p">):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">results</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</span><span class='line'><span class="k">if</span> <span class="ow">not</span> <span class="n">results</span><span class="p">:</span>
</span><span class='line'>    <span class="n">results</span> <span class="o">=</span> <span class="n">do_a_ton_of_work</span><span class="p">()</span>
</span><span class='line'>    <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span>
</span><span class='line'><span class="c"># ...</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Each time I tried this the results weren't added to the cache. After about 15 minutes of digging, I realized that the dataset was larger than memcached's limit for record sizes. When that happens, the call to <code>cache.set()</code> (maddeningly) fails silently.</p>

<p>So I couldn't cache the whole thing, but this turned out to be a useful
exercise. I realized I didn't need to cache the entire set as one big value. I could chunk the dataset in the same size chunks as were being paginated (currently 100 links). So now, the code looks like this:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Caching chunks  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="n">request</span><span class="p">):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">page</span> <span class="o">=</span> <span class="n">get_page</span><span class="p">(</span><span class="n">request</span><span class="p">)</span> <span class="c"># for pagination</span>
</span><span class='line'>
</span><span class='line'><span class="n">results</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</span><span class='line'><span class="k">if</span> <span class="ow">not</span> <span class="n">results</span><span class="p">:</span>
</span><span class='line'>    <span class="n">results</span> <span class="o">=</span> <span class="n">do_a_ton_of_work</span><span class="p">()</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
</span><span class='line'>        <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">results</span><span class="p">[</span><span class="n">index</span><span class="p">:</span><span class="n">index</span><span class="o">+</span><span class="mi">99</span><span class="p">])</span>
</span><span class='line'><span class="c"># ...</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>Cache Eviction</h2>

<p>One thing to remember is that caches are not some magical never-ending source of storage. Memcached stores items in memory, of which it has a limited supply (limited by you, that is). When a cache is using the full amount of memory allotted and gets a request to add something new, a choice has to be made. This choice is known as the cache's <em>eviction policy</em>, since a record is about to be 'evicted' from the cache. Memached uses a variant of LRU, or Least Recently Used, eviction. Glossing over the topic of page allocation and sizing, which you can read about on Memcached's wiki, the cache looks for the least recently used item and overwrites it with the new value. This approach has good <em>temporal locality</em>, since something that was used recently (especially in web programming), is likely to be used again soon. Things not used for a while are less likely to be used again soon, and thus are good candidates to remove from the cache. For linkrdr, this has a few useful side effects. The view's cached items are likely to be used soon after they are created (as a user browses their links) and then not used at all (when they leave the site), which perfectly matches the cache eviction policy. Also, using small chunks instead of the whole dataset allows eviction with more granularity, so a user's entire cache isn't lost all at once.</p>

<h2>Which is Nice, Except...</h2>

<p>But there are some problems with this approach. For one, the first (uncached) request still takes the full 3.5 seconds. The first request being the most important one, this is not ideal. Second, we have to deal with updates to the dataset that would require a recalculating of the scores of each of the links (for example, when a user adds a new feed or linkrdr is updating feed items). Using some additional features of Memcached, we can overcome these obstacles as well.</p>

<p>Let's deal with updates to the dataset first. Django supports "versioning" of cache records. If you specify a version number in your <code>cache.set(key, value, version=my_version)</code> call, then a corresponding <code>cache.get(key, version=some_other_version)</code> call will not return any data. Using versioning, we can change things around and store the user's current 'version' in the cache. When we want to get the cached dataset, we specify the user's cached version number. In this way, we are able to <em>invalidate</em> old cache entries without searching through the cache for all of a user's cached items. An example will help clarify:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Memcached with versioning  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="n">request</span><span class="p">):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">version</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</span><span class='line'><span class="k">if</span> <span class="ow">not</span> <span class="n">version</span><span class="p">:</span>
</span><span class='line'>    <span class="n">version</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class='line'>    <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">version</span><span class="p">)</span>
</span><span class='line'><span class="n">page</span> <span class="o">=</span> <span class="n">get_page</span><span class="p">(</span><span class="n">request</span><span class="p">)</span> <span class="c"># for pagination</span>
</span><span class='line'>
</span><span class='line'><span class="n">results</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="mi">100</span><span class="p">),</span> <span class="n">version</span><span class="o">=</span><span class="n">version</span><span class="p">)</span>
</span><span class='line'><span class="k">if</span> <span class="ow">not</span> <span class="n">results</span><span class="p">:</span>
</span><span class='line'>    <span class="n">results</span> <span class="o">=</span> <span class="n">do_a_ton_of_work</span><span class="p">()</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
</span><span class='line'>        <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">id</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">results</span><span class="p">[</span><span class="n">index</span><span class="p">:</span><span class="n">index</span><span class="o">+</span><span class="mi">99</span><span class="p">],</span> <span class="n">version</span><span class="o">=</span><span class="n">version</span><span class="p">)</span>
</span><span class='line'><span class="c"># ...</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Now, when a user adds a feed and the link scores need to be recalculated, we can simply increment his or her version so that the next <code>cache.get()</code> will be a cache miss.</p>

<p>But wait, I just said we <em>want</em> a cache miss. That can't be right. What we'd <em>really</em> like is for the links to be recalculated <em>and cached</em> and the old values invalidated. To accomplish this without interrupting the user (remember recalculating takes a couple seconds), we fire off a Celery task to ansynchronously recalculate the results, update the cache, and update the user's version. This way, the user can continue using the site and, if they take longer than 3-4 seconds between adding a feed and looking at their new links, we'll have the results <em>prefetched</em>. The idea of prefetching is a powerful one, and it solves the other problem (the first visit to a page results in a cache miss) as well. When linkrdr updates the feeds, it also caches the results for frequent users of the site (which it determines using yet more cached data). This way, the people who use the site the most experience instant page loads. Infrequent users will experience at most one slow page load.</p>

<p>It would be nice if we could prefetch every user's data after every update, but linkrdr has neither the memory nor computing power to do this. In a way, this is a good thing, because throwing more hardware at a problem doesn't require much thought. Many of the interesting technical challenges linkrdr faces come about because of the constraints on memory and CPU availability. Since I'm running on a single VPS, I have to get a bit creative with some of my solutions. If I didn't have to consider these things, the site would likely be worse for it and would certainly be less interesting to work on. The current caching solution can scale with the site without straining resources too much.</p>

<p>The preceeding is <a href="http://www.linkrdr.com">linkrdr</a>'s current approach to caching. One interesting side note: I'm currently investigating running memcached in a distributed manner using the other VPS I use to host <a href="http://www.illestrhyme.com">IllestRhyme</a>. Since the latter site has far more spare CPU cycles, computation can be partially offloaded to the second machine and the results stored in a distributed cache (which Memcached and Django helpfully support out of the box). Aditionally, sprinkling in other types of caching (like file based caching) may make it possible to prefetch all data for all users.</p>

<p>Questions or comments on <em>Django Memcached: Optimizing Django Through Caching</em>? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How linkrdr went semi-viral]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/21/how-linkrdr-went-semi-viral/"/>
    <updated>2012-02-21T04:34:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/21/how-linkrdr-went-semi-viral</id>
    <content type="html"><![CDATA[<p>I was a bit under the weather this past weekend, but it turns out I
wasn't the only thing to go viral. Below is a brief story of how <a href="http://www.linkrdr.com">linkrdr</a> enjoyed it's first encouter with virality.</p>

<h2>Background</h2>

<p>Before Saturday, linkrdr had about 10 users, who had figured out a way
to signup without me really providing one. Sometime Thursday evening, I
believe, I slapped a 'Beta' sticker on the front page, cleaned some
stuff up, and declared linkrdr open for business. Come the weekend, I
was under the weather and not feeling like working on anything, so I
didn't check any of my sites until Monday at 4pm. I cruised over to my
<a href="http://getclicky.com/66528953">Clicky</a> dashboard and took a look at the
stats for this blog. Then something caught my eye...</p>

<p><img src="http://66.228.46.113/static/img/linkrdr_growth.png" title="linkrdr visits per day" ></p>

<!--more-->


<h2>"Uh oh"</h2>

<p>The graph for linkrdr, which is usually totally flat, had suddenly
shot up almost vertically. I quickly checked the number of users via the
django console and felt a pit in my stomach: <strong>720 users had signed up
in the past 24 hours</strong>. I caught my breath, then checked how many total
links linkrdr was managing. I read the number three times. I couldn't
believe it: <strong>109,214 links</strong> across about 3,700 feeds. I fired up my
browser to see if the site had melted down. To my surprise, it was
pretty responsive. After clicking around more and convincing myself the
server wasn't on fire, I did a little <a href="http://getclicky.com/66528953">Clicky</a> style investigating.</p>

<p>It became clear rather quickly that most of my links were coming from
two sources: <a href="http://www.startupsea.com">startupsea.com</a>, a new
startup-roundup type site I hadn't heard of, and
<a href="http://www.scripting.com">scripting.com</a>. When I saw the second site,
my heart skipped a beat. I'm very familiar with scripting.com, the blog
of <a href="http://en.wikipedia.org/wiki/Dave_Winer">Dave Winer</a>. I checked out
scripting.com and sitting there on his list of links was a link to
linkrdr. He had also tweeted about it to his <strong>75,000</strong> followers.
Between the two sites, linkrdr had gone mini-viral.</p>

<h2>Aftermath</h2>

<p>I quickly decided that I needed to bullet-proof the site (how I did so
will be the topic of my next post). I was proud
that the site could handle the drastic uptick in flow, but I wasn't
going to leave anything to chance. Over the past 18 hours, I've been
adding features that users have been clamoring for (OPML import has been
added, for one), fixing bugs, and generally cleaning things up. It's still too early to
tell if this was just a one-off blip, as the US public had Monday off of
work. Tuesday morning will be an interesting one. Let's hope linkrdr
gets more viral-love!</p>

<p>Questions or comments on <em>How linkrdr Went Semi-Viral</em>? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing linkrdr]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/10/introducing-linkrdr/"/>
    <updated>2012-02-10T00:49:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/10/introducing-linkrdr</id>
    <content type="html"><![CDATA[<p>I started work on a new site on Monday:
<a href="http://www.linkrdr.com">linkrdr</a>. It's the next
generation feed reader for people who subscribe to tens or hundreds of
feeds. linkrdr aggregates your feeds <strong>but more importantly, your links</strong>. It ranks
links according to a relevance formula. Purely chronological based readers
are just <em>terrible</em> at managing a mountain of links.</p>

<p>The idea for linkrdr came from <a href="http://news.ycombinator.com/item?id=3555923">a Hacker News post</a> describing exactly the
problem linkrdr solves. I realized I had exactly the same problem as the
submitter: too many links, too little time. I don't want to miss
out on a quality post on a blog that doesn't publish very often. At the
same time, if there's a link that's showing up in a number of my feeds,
it's a good bet that it's worth reading.</p>

<!--more-->


<p>linkrdr calculates the relevance of a feed entry using two
metrics: number of feeds appearing in and feed post frequency. If you
subscribe to /r/programming and www.somerandomphysicsblog.com, you don't
want new posts to have the same weight. /r/programming is updated
constantly, so the chance that an individual entry in the feed is worth
looking at is smaller than from a blog which updates once a week.</p>

<p>On the other hand, if I subscribe to /r/programming and a number of
other programming feeds, and there's a link appearing in a bunch of
them, I probably want to read it. linkrdr balances the two metrics to
come up with a score for each entry in your feeds. It then presents your
entries sorted by score, with what it determines to be the most relevant
at the top.</p>

<p>Another problem with feed aggregators is that it's not always clear
where something came from. In linkrdr, all entries list their sources
with a link to the original page. So if a popular story was in four of
your feeds, you would see one entry with "Citations" showing all of the
feeds it appeared in.</p>

<p>You can (that is, you will be able to) use linkrdr to find new feeds to
subscribe to as well. For each entry in your feed you'll see a "Show
other feeds this appeared in" link. This will give you a list of all the
currently tracked feeds that had the link, minus the ones you already
subscribe to.</p>

<p>To find new content <em>not</em> in your feeds, you'll see a list of popular
entries as determined by the number of feeds they appear in. If everyone
on the Tubes is linking to something, it might be worth checking out
even if it's not in one of your feeds.</p>

<p>linkrdr is by not even close to finished , nor even particularly useable at the
moment, but progress is coming quickly. I'll describe more of linkrdr's
functionality in future posts. For now, if you want to sign up for it
while it's free (I may charge a one-time fee if I think the service is
actually useful), go ahead and do so at <a href="http://www.linkrdr.com">linkrdr.com</a>.
I can't guarantee stuff will work but signup at least should.</p>

<p>Questions or comments on <em>Introducing linkrdr</em>? Let me know in the comments below.
Also, follow me on Twitter to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
</feed>
