<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: c++ | Hackers Gonna Hack]]></title>
  <link href="http://www.jeffknupp.com/blog/categories/c-/atom.xml" rel="self"/>
  <link href="http://www.jeffknupp.com/"/>
  <updated>2012-07-10T06:02:38-04:00</updated>
  <id>http://www.jeffknupp.com/</id>
  <author>
    <name><![CDATA[Jeff Knupp]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Software Optimization: A Systematic Approach]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/07/10/software-optimization-a-systematic-approach/"/>
    <updated>2012-07-10T05:25:00-04:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/07/10/software-optimization-a-systematic-approach</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>What follows is the first in a series of articles on developing a formal methodology
for software optimization I've been working on for some
time. Each week, I'll post the newest installment here (they're all written, I'm just
wary of dumping the whole thing here all at once). Feedback is of course welcome and
encouraged. The complete version will be available in epub format, as well as online
in a more readable style. I hope you enjoy reading this half as much as I enjoyed
writing it.</p>

<h2>Part 1: A Primer</h2>

<p>Software Optimization is a topic which receives a curious lack of coverage in
most Computer Science curricula. Even on the Internet, there are few resources
which approach the topic in any kind of structured manner.  Typically, a
programmer blogs about how they made a certain piece of code x times faster and
describes the series of changes made. These "optimization anecdotes" are
entertaining but rarely useful as a way to learn how to optimize one's own code.
<em>The main problem in learning how to optimize code is that no one is actually
teaching it.</em></p>

<p>Especially in the enterprise, optimization is poorly understood by many developers. There are a number
of reasons for this: lack of understanding about OS level operations, lack of familiarity
with tools to aid optimization, and the difficulty in correctly anticipating bottlenecks
in one's code, to name a few. Junior developers, lacking the proper experience
to even know where to start, often practice cargo-cult optimization, applying
optimizations they've seen or read about elsewhere without determining if they're impactful and
appropriate.</p>

<p><em>It's time the practice of software optimization had a homepage.</em></p>

<p>This series of articles will present a formalized, structured approach to
software optimization. While most of the examples will focus on Linux, the
methodology and ideas are universally applicable. A programmer on any other
OS should have no problem following along and get just as much
out of it. An embedded systems developer will find the low level details
different but the approach the same.</p>

<!--more-->


<h3>Reality Check</h3>

<p>This is the part where I'm supposed to tell you that after reading this series
you'll be ready to amaze your boss by fixing all of the slow-performing
code in whatever it is you work on. Unfortunately, that won't be the case. I must be
very clear about this point lest anyone have unreasonable expectations: Even
after reading this entire series and all of the background material mentioned,
becoming a skilled practitioner of optimization will likely require at least ten
years of professional development experience and at least two to three years
working on a performance critical system. It is not a skill one picks up all at
once; rather, it draws on the knowledge built over one's career.
The study of optimization is not done in isolation. It necessarily includes a
wide variety of domains such as OS interaction, hardware design, high performance data
structures and algorithms, and testing methodologies.</p>

<p>But there's a very bright silver lining. <em>I know of no better way to become a
better programmer than to study optimization</em>. The knowledge you pick up along
the way about topics you don't encounter in your day to day work
will benefit you the rest of your career. You'll write better
code, design more coherent systems, find and fixing bugs more quickly, and
perhaps most importantly, be able to think critically and reason about software
systems.</p>

<p>And now, we begin...</p>

<h3>Lesson 1: Building a Foundation</h3>

<p>To effectively optimize code across a variety of domains, you need to become a technical
renaissance wo/man. There's no way around it: optimization takes at least a general understanding
of a <em>lot</em> of different areas of computing. Below are areas of particular interest.</p>

<h4>Hardware for Software People</h4>

<p>Many developers have an aversion to learning about hardware. Get over it. You'll need a good
background in the topics below to be truly effective at low-level optimizations. All of them
are far too broad to cover adequately here. For the topic of caching, because of how often if affects
performance, I've included summaries of relevant information mostly aimed at refreshing the knowledge
of those already familiar.</p>

<h5>Memory</h5>

<h6>Recommended Reading</h6>

<p>The seminal modern work on Linux memory is surely libc maintainer Ulrich Drepper's <a href="http://lwn.net/Articles/250967/">What Every Programmer Should Know About Memory</a>.  Honestly, There's not much he doesn't cover, so this is it for recommended readings.</p>

<h6>Cache architectures</h6>

<p>Modern CPUs have on die memory in order to facilitate caching, typically used to cache the contents of recently read or written values. The basis for singling out recently used values is the principal of <em>temporal locality</em> which states that, all things being equal, a resource used recently is likely to be needed again soon. Since access to system memory is comparatively expensive, caches operate not on individual addresses but "cache lines", fixed size chunks of memory representing contiguous physical memory. Based on the idea of <em>spatial locality</em>, or that a resource physically close to one recently used will likely be used soon, caching memory in chunks has the added benefit that most programs access data reasonably sequentially. While the cache is meant to benefit programs without their needing to explicitly attempt to make use of it (or, indeed, even know of its existence), it can also play an adversarial role in low-level optimizations. Designing programs that work with the CPU's cache is critical to good performance in highly optimized routines.</p>

<h6>Cache Coherence</h6>

<p>Multi-processor (and multi-core) architectures naturally require a consistent view of memory across all processors. Otherwise, threads running on different CPUs making a change to the same memory address could create an inconsistent state by setting their copy of the same element to different values. To compensate, CPU architectures implement <em>cache coherency protocols</em> using a variety of methods. Often, reading and writing have separate rules governing the actions that must be performed after the operation completes. The protocols differ not just between CPU manufacturers but between CPU families as well, making it somewhat difficult to make generalizations about "modern" cache coherency. That said, the information is widely available for most commercial processors and the implementation is usually based on one of a number of well-understood algorithms. When optimizing for memory access patterns, one must be mindful of how multiple threads on different CPUs operating on shared data can be <em>less</em> efficient than a single thread performing the same work because of cache coherency issues.</p>

<h6>False sharing</h6>

<p>Related to coherency, false sharing occurs when one thread writes and one or more threads read from logically separate areas of memory that happen to occupy the same cache line. These addresses in memory need not be related to one another in the host program (though their short distance usually means they are in some way). When the threads are running on the same core this is not a problem. When running on different cores, however, each write performed by one thread invalidates the cache line the readers are accessing. The effects of false sharing even on extremely simple programs can be dramatic. Herb Sutter has a great article <a href="http://www.drdobbs.com/go-parallel/parallel/eliminate-false-sharing/217500206">Eliminate False Sharing</a> that covers the topic with simple examples.</p>

<h6>Ping-Ponging</h6>

<p>When false sharing occurs with a frequently used memory location, the valid cache line will effectively bounce back and forth between the cores involved. This is known as "ping-ponging" or "thrashing". Of course, ping-ponging need not be caused by false sharing. Any access pattern that results in multiple resources competing for the same cache line will exhibit this behavior.</p>

<h5>CPU</h5>

<ul>
<li>CPU pipeline</li>
<li>Instruction cache</li>
<li>Branch prediction</li>
<li>Logical versus physical cores (or why you're dual core CPU reports more than two cores)</li>
<li>Extended instruction sets</li>
</ul>


<h5>Disk</h5>

<ul>
<li>Relative access speed</li>
</ul>


<h4>Know Your OS</h4>

<p>You should try to understand your target OS as intimately as possible. Different Linux kernel versions
can vary a great deal in implementation efficiency of both kernel and user space operations. For the same
reason, you should also be familiar with the particular version of the Linux distro you're running.
A good way to learn about what's slow in your kernel or Linux distro is to read the
change notes for all releases <em>after</em> the one you're using. You'll see bugs the developers
fixed as well as operations they optimized. In addition, they'll normally have an
article or series of emails describing the change by first giving background as to why it's slow. This
will help you anticipate possible sources of slowness.</p>

<p>The list below is a good overview of topics important to optimization in general.</p>

<h6>Virtual Memory</h6>

<ul>
<li>Implementation</li>
<li>Cache interaction</li>
</ul>


<h6>Atomic Operations</h6>

<ul>
<li>Implementation</li>
</ul>


<h6>Threading</h6>

<ul>
<li>Synchronization primitives</li>
<li>Context switching</li>
<li>Scheduling</li>
</ul>


<h6>User Space vs Kernel Operations</h6>

<ul>
<li>Affect on thread scheduling</li>
</ul>


<h6>IPC</h6>

<ul>
<li>System V vs POSIX shared memory</li>
<li>UNIX domain sockets</li>
<li>Memory mapped files</li>
<li>Implementations</li>
</ul>


<h3>Lesson 2: Wherein You Resist the Urge to Guess</h3>

<p>Ask any programmer what the slowest portion of their system is and they'll likely mention a subsystem
with externally visible slowness. If you ask them <em>why</em> it's slow, they'll be happy to tell you the
exact portion of that subsystem's code responsible for the slowness.</p>

<pre><code>They're almost certainly wrong
</code></pre>

<p>There is a key truth to be mindful of while doing optimization work: <em>programmers are, as a rule,
terrible at anticipating at the cause of slowness in their application.</em> This is counterintuitive but almost always
true. Time and time again developers will go off to "make something faster" without systematically <em>proving</em> the
cause of slowness and come back two weeks later with 700 lines of hand optimized code that have precisely <strong>zero</strong> impact
on overall performance. There's a good reason for this, although it's not an especially satisfying one: computers are complicated.
Even if you are aware of every cause of every performance issue ever, you'll still have an extremely difficult time anticipating
the cause of slowness through reasoning alone. The interaction between the different subystems, logical units within those subsystems,
the operating system, the hardware, etc is just too complicated to be able to work out in your head. If it wasn't, we would never
have performance issues or, more tellingly, bugs in our software.</p>

<h4>Families of Tools</h4>

<p>Luckily, you don't have to rely on intuition when optimizing. There are scores of tools, both open and closed source, designed
to help developers find the reasons for a program's slowness. They can generally be divided into a few classes of tools:</p>

<h5>Function Call Profilers</h5>

<p>Profilers are tools that create an <em>execution profile</em> of a running program. There are two general types of profilers: <em>statistical profilers</em> and <em>instrumenting profilers</em>. Statistical profilers are typically added in at link time and take 'snapshots' of the executing program. These snapshots record the call stack of each thread of execution. Over time, the aggregate of these snapshots create a reasonably complete picture of the relative frequency of various operations (i.e. function calls). The other type of profiler interposes itself in some manner and records <em>every</em> function call instead of a sampling. This higher level of detail comes at a cost: your program will typically run <strong>noticably</strong> slower while being profiled.</p>

<h5>Cache profilers</h5>

<p>Cache profilers are used to determine the memory access patterns of a program and how effective it is at utilizing the CPU's data cache. For each memory reference, the profiler will determine if the value was cached and at what cache level it was retrieved from. It also records cache misses, where the data must be retrieved from main memory.</p>

<p>Cache profilers are also usually capable of profiling instruction cache access as well. Similar to data cache, profilers typically record the count and source of cache hits and misses, as well as the cache level (if any) that eventually was found to contain the item in question.</p>

<p>Lastly, a number of cache profilers are able to profile <em>branch mispredictions</em>. When the CPU encounters a conditional branch in your code, like an if statement, it makes an (hopefully) informed guess as to which condition is more likely to be true. It can than prefetch the instructions for that branch of execution (or, depending on the architectures, multiple branches). In doing so, it avoids the need to wait until the CPU actually executes the conditional statement to fetch more instructions. Since CPU's use <em>pipelining</em> to increase instruction throughput, waiting to see which conditional branch must be executed has a knock-on effect on subsequent instructions. If the CPU finishes executing a conditional instruction but the next instruction is not available (perhaps because the wrong branch was predicted), it must wait for the next set of instructions to be fetched, known as a <em>CPU stall</em>.</p>

<h5>Heap profilers</h5>

<p>Inevitably in your optimization journey you'll come to realize a simple fact: dynamic allocation is <em>slow</em>. Really slow. You'll look at the profile output for a program and see all of the time being spent in '''malloc''' and '''free''' Enter heap profilers. Rather than telling you how much <em>time</em> a portion of your code is taking, a heap profiler will tell you how much memory that portion is allocating. Many times, especially in enterprise development (for a reason I still don't really understand), objects are allocated on the heap, used as local variables, and destroyed without passing ownership elsewhere. This is both unnessecary and wasteful. Stack objects are created statically and accessed via an offset from the stack pointer. Using them is as close to "free" as you're going to get. Heap allocations are another thing altogether. You need to fetch a portion of memory from the OS which, as we discussed in describing cache profilers, is not always a lightening fast operation. Adding in virtual memory operations and the overhead of system calls in general and you've got one <em>slow</em> operation for zero benefit. Also, physical memory is a shared resource, so you better be sure you free it lest you create a memory leak and slow down or crash the machine.</p>

<h4>List of Profilers</h4>

<p>Below are links to some profilers for Linux systems. The valgrind suite is usually my go-to set of profiling tools. That said, I've
personally used almost every tool on the list. All are helpful in some way.</p>

<ol>
<li><a href="http://www.valgrind.org">Valgrind</a></li>
<li>oprofile: part of the Linux kernel. Check your distro to determine how to install.</li>
<li><a href="http://software.intel.com/en-us/articles/intel-vtune-amplifier-xe/">VTune</a>, Intel's profiler for Intel CPUs</li>
<li><a href="http://developer.amd.com/tools/CodeAnalyst/Pages/default.aspx">CodAnalyst</a> AMD's profiler for AMD CPUs</li>
<li><a href="http://en.wikipedia.org/wiki/Gprof">gprof</a> The GNU profiler, part of GNU binutils</li>
<li><a href="http://code.google.com/p/gperftools/">Google PerfTools</a> Now maintained outside of Google and renamed 'gperftools'.</li>
</ol>


<p><em>This brings us to the end of Part 1 of the series. Part 2 gets into the meat of how to approach software optimization. Look for
here it next week.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Optimizing Django Views With C++]]></title>
    <link href="http://www.jeffknupp.com/blog/2012/02/15/optimizing-django-views-with-c-plus-plus/"/>
    <updated>2012-02-15T09:55:00-05:00</updated>
    <id>http://www.jeffknupp.com/blog/2012/02/15/optimizing-django-views-with-c-plus-plus</id>
    <content type="html"><![CDATA[<p>In my <a href="http://www.jeffknupp.com/blog/2012/02/14/profiling-django-applications/">previous post</a> I outlined the method by which one goes about profiling a Django application. I used a view from <a href="http://www.linkrdr.com">linkrdr</a> as an example. That view is responsible of aggregating, ranking, and sorting all of the links in a user's feeds (RSS, atom, Twitter, etc). The code from the post was an early, simplistic implementation of the view. I have, however, a much more robust scoring algorithm, written in Python, which I planned to used on the site.</p>

<p>You may have caught the word 'planned' in there. The algorithm turned out to be too slow. Rather, my Python implementation of the algorithm
was slower than what I deemed acceptable. After thinking of various architectural changes that could be made to solve the problem, I settled on a somewhat radical solution for a Django developer: <strong>I implemented the view in C++</strong>.</p>

<p>I realize that not every Django developer knows C++, nor should they, but those that do should realize it's a viable tool available when Python is just too slow. Eventually, you may get to a point where you can't really optimize your Python code any more. In this case, profiling will show that most of your time is spent in Python library calls. Once you hit that point, you've either written a horribly inefficient algorithm or you've got a problem not suited for Python.</p>

<p>When I realized I had hit that point with my view code, I panicked.
<em>'What more is there to do?'</em> I wondered. Then I rememberd a work
project where I had written some C++ code that interfaced with Python.
From a technical perspective, there was nothing stopping me from
implementing some aspects of my Django app in C++ (besides the fact
that it's <em>excruciating</em> to write in coming from Python). Since linkrdr
is a single-person project, there are no teammates who need to grok the
code. I'm free to implement it as I wish.</p>

<!--more-->


<h2>Setting Up</h2>

<p>Having written "pure" C++/Python interoperability code before, and not
wanting to see <code>Py_XDecRef</code> again, I decided I would use boost::python. To begin, I made sure I had the latest <a href="http://www.boost.org">Boost</a>
libraries and a recent version of gcc installed so I could use C++11
features, which really are rather nice. After building the newest
version of the boost::python library, I set out to learn how to actually
use the thing. It turned out to be incredibly easy.</p>

<p>boost::python wraps a number of Python datatypes for you: <code>object</code>
represents a generic Python object, <code>list</code> is a list, and so on. Since
Python is dynamically typed, there really aren't a whole lot of these.
'Everything is an Object' means that everything is a
boost::python::object and can be accessed in that way.</p>

<p>In addition to primitive and container type wrappers, boost provides a
clear and concise mechanism to make C++ classes and functions visible to Python. I had
a simple class in the code of my previous entry name <code>LinkScore</code>. It
was basically a C struct with a list of objects and an integer. The C++
code for it is:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>A simple C++ class  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'><span class="k">using</span> <span class="k">namespace</span> <span class="n">boost</span><span class="o">::</span><span class="n">python</span><span class="p">;</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">class</span> <span class="nc">LinkScore</span>
</span><span class='line'><span class="p">{</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">public</span><span class="o">:</span>
</span><span class='line'>    <span class="n">LinkScore</span><span class="p">()</span> <span class="p">{}</span>
</span><span class='line'>    <span class="n">LinkScore</span><span class="p">(</span><span class="k">const</span> <span class="n">object</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">link</span><span class="p">,</span> <span class="kt">int</span> <span class="n">score</span><span class="p">)</span> <span class="o">:</span> <span class="n">score_</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="n">links_</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">link</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'><span class="n">list</span> <span class="n">links_</span><span class="p">;</span>
</span><span class='line'><span class="kt">int</span> <span class="n">score_</span><span class="p">;</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>If you're thinking my data members should be private, guess what: I
don't care. That's part of the joy of working on code that only you will
use. You get to write it and use it however you want.</p>

<h2>The Details</h2>

<p>Anyway, the boost::python code to make this callable from Python is:
<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>boost::python code for Python interoperability  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">class_</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="n">LinkScore</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;(</span><span class="s">&quot;LinkScore&quot;</span><span class="p">,</span> <span class="n">init</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="n">object</span><span class="p">,</span> <span class="kt">int</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;())</span>
</span><span class='line'>    <span class="p">.</span><span class="n">def_readwrite</span><span class="p">(</span><span class="s">&quot;links&quot;</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">LinkScore</span><span class="o">::</span><span class="n">links_</span><span class="p">)</span>
</span><span class='line'>    <span class="p">.</span><span class="n">def_readwrite</span><span class="p">(</span><span class="s">&quot;score&quot;</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">LinkScore</span><span class="o">::</span><span class="n">score_</span><span class="p">);</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Really, it couldn't be more simple. The <code>&lt;Python.h&gt;</code> way of
accomplishing this involves setting a struct with like 40 values to
declare each class. I was happy to not have to bother with that.</p>

<p>The actual code for my view is a free function called <code>get_scores</code>.
Here's a brief snippet:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>C++ code to be called by my Django view  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'><span class="k">using</span> <span class="k">namespace</span> <span class="n">boost</span><span class="o">::</span><span class="n">python</span><span class="p">;</span>
</span><span class='line'><span class="k">using</span> <span class="n">namspace</span> <span class="n">std</span><span class="p">;</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">class</span> <span class="nc">CompareObject</span> <span class="p">{</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">public</span><span class="o">:</span>
</span><span class='line'>  <span class="kt">bool</span>  <span class="k">operator</span><span class="p">()(</span><span class="k">const</span> <span class="n">LinkScore</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">l</span><span class="p">,</span> <span class="k">const</span> <span class="n">LinkScore</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">r</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">l</span><span class="p">.</span><span class="n">score_</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">r</span><span class="p">.</span><span class="n">score_</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="p">};</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">list</span> <span class="n">get_scores</span><span class="p">(</span><span class="n">object</span> <span class="n">links</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">object</span> <span class="n">utility</span> <span class="o">=</span> <span class="n">import</span><span class="p">(</span><span class="s">&quot;links.utility&quot;</span><span class="p">);</span>
</span><span class='line'><span class="n">set</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="n">LinkScore</span><span class="p">,</span> <span class="n">CompareObject</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">seen_links</span><span class="p">;</span>
</span><span class='line'><span class="n">list</span> <span class="n">python_seen_links</span><span class="p">;</span>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">len</span><span class="p">(</span><span class="n">links</span><span class="p">);</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="k">const</span> <span class="n">object</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">link</span> <span class="o">=</span> <span class="n">links</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span class='line'>    <span class="n">LinkScore</span> <span class="n">score</span> <span class="o">=</span> <span class="n">LinkScore</span><span class="p">(</span><span class="n">link</span><span class="p">,</span> <span class="n">score_link</span> <span class="p">(</span><span class="n">link</span><span class="p">,</span> <span class="n">links</span><span class="p">));</span>
</span><span class='line'>    <span class="k">auto</span> <span class="n">iter</span> <span class="o">=</span> <span class="n">seen_links</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">score</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="n">iter</span> <span class="o">!=</span> <span class="n">seen_links</span><span class="p">.</span><span class="n">end</span><span class="p">())</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="c1">// Do stuff</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="k">else</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="c1">// Do other stuff</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'><span class="c1">// TODO: Optimize this</span>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="n">i</span> <span class="o">=</span> <span class="n">seen_links</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">seen_links</span><span class="p">.</span><span class="n">end</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="n">python_seen_links</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'><span class="k">return</span> <span class="n">python_seen_links</span><span class="p">;</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>If you know C++ and Python, it's almost like reading a mix of the two.
The above, however, is valid C++ code and is the interface that Python
uses to call into my scoring library. To expose this function to Python,
all that's needed is <code>def ("get_score", get_score);</code> within a
<code>BOOST_PYTHON_MODULE</code> block, which names the module to be imported.</p>

<p>When I was done writing the C++ code, I compiled it using gcc and Boost's bjam build tool,
set my LD_LIBRARY_PATH to pickup libboost_python.so, and fired up a
shell from manage.py (well, a 'shell_plus' really). I used the cProfile
module to compare the C++ version of the view with the Python version of
the view. The results were satisfying: an 8x speedup with the C++
version.</p>

<p>To call the C++ code, I just needed to make sure the .so generated was
on my PYTHON_PATH. I could then <code>import</code> it like a normal Python
library. I added it to my views.py and ran my unit tests. After they
passed, I committed everything and put the new code through it's paces
on the development web server. The reponse time was noticably improved,
with the view being served seemingly instantaneously.</p>

<h2>Wrap Up</h2>

<p>I realize this is not an optimization option avaiable to everyone, but
it <em>is</em> an option. Python is a fantastic language and Django is a nice
framework. When you need raw speed for computationally expensive
procedures, though, nothing beats getting closer to the metal. Overall,
I'm quite happy with the results and how easy it was to implement. I
will refrain from writing any more C++ code for linkrdr unless
absolutely necessary. It's nice to know, however, that the option is there.</p>

<p>Questions or comments on <em>Optimizing Django Views With C++</em> ? Let me know in the comments below. Also, <a href="http://www.twitter.com/jeffknupp/">follow me on Twitter</a> to see all of my blog posts and updates.</p>
]]></content>
  </entry>
  
</feed>
